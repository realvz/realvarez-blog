{
  "version": "https://jsonfeed.org/version/1",
  "title": "Re Alvarez Parmar&#39;s Blog",
  "home_page_url": "https://blog.realvarez.com",
  "feed_url": "https://update-me.com/feed/feed.json",
  "description": "A collection of writing by Re Alvarez Parmar",
  "author": {
    "name": "",
    "url": ""
  },
  "items": [{
      "id": "https://blog.realvarez.com/posts/k8s-gcr-io-mirror/",
      "url": "https://blog.realvarez.com/posts/k8s-gcr-io-mirror/",
      "title": "Use containerd to handle k8s.gcr.io deprecation",
      "content_html": "<p>The Kubernetes community is getting ready for yet another major change. Until fall of 2022, <code>k8s.gcr.io</code> container registry hosted many Kubernetes community-managed containers images like Cluster Autoscaler, metrics-server, cluster-proportional-autoscaler. The “<a href=\"http://gcr.io\">gcr.io</a>” part in the registry is Google Cloud Registry. In order to be vendor neutral, the community is moving away from using Google Cloud Registry to host container images.</p>\n<p>As a result, starting March 20th, traffic from the old <code>k8s.gcr.io</code> registry is being redirected to <code>registry.k8s.io</code>. The older <code>k8s.gcr.io</code> will remain functioning for sometime but it is eventually getting deprecated.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/13FE78CC-1DDD-47D9-B875-EE3FB15F916E/FC421666-8104-4CD9-8C7F-8E4F4BCE2B83_2/6olkWYEK1kl10toAonqYL40P1ZSQIUY2N6iHRwId78kz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<h2 id=\"what%E2%80%99s-the-impact%3F\">What’s the impact? <a class=\"direct-link\" href=\"#what%E2%80%99s-the-impact%3F\">#</a></h2>\n<p>The change that occurred six days after Pi day is unlikely to cause major problems. There are some edge cases. But unless you operate in an airgapped or highly restrictive environment that applies strict domain name access controls, you won’t notice the change.</p>\n<p>This doesn’t mean that there’s no action required. Now is the time to scan code repositories and clusters for usage of the old registry. Failing to act will result in cluster components failing.</p>\n<p>Once the old registry goes away, <strong>Kubernetes will not be able to create new Pods</strong> (unless image is cached) if the container uses an image hosted on <code>k8s.gcr.io</code>.</p>\n<h2 id=\"what-do-you-need-to-change%3F\">What do you need to change? <a class=\"direct-link\" href=\"#what-do-you-need-to-change%3F\">#</a></h2>\n<p>Cluster owners and development teams have to ensure they are not using any images stored in the old registry. The change is fairly simple. It's pretty simple, really.</p>\n<p>You need to change your manifests to use <code>registry.k8s.io</code> container registry.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/13FE78CC-1DDD-47D9-B875-EE3FB15F916E/EB0981CC-3DC8-49EE-A6F5-A857A69CC949_2/D0F0mQ2JMAl55JNCuS66lUylRznVZywEMdojiRqkc0sz/Image.png\" alt=\"Image.png\"></p>\n<p>You can find out which Pods use the old registry using <code>kubectl</code>:</p>\n<pre class=\"language-bash\"><code class=\"language-bash\">kubectl get pods --all-namespaces -o <span class=\"token assign-left variable\">jsonpath</span><span class=\"token operator\">=</span><span class=\"token string\">\"{.items[*].spec.containers[*].image}\"</span> <span class=\"token operator\">|</span><span class=\"token punctuation\">\\</span><span class=\"token number\">0</span><span class=\"token punctuation\">;</span><span class=\"token number\">31</span><span class=\"token punctuation\">;</span>37M0<span class=\"token punctuation\">;</span><span class=\"token number\">31</span><span class=\"token punctuation\">;</span>38m<br><span class=\"token function\">tr</span> -s <span class=\"token string\">'[[:space:]]'</span> <span class=\"token string\">'\\n'</span> <span class=\"token operator\">|</span><span class=\"token punctuation\">\\</span><br><span class=\"token function\">sort</span> <span class=\"token operator\">|</span><span class=\"token punctuation\">\\</span><br><span class=\"token function\">uniq</span> -c <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> -i gcr.io</code></pre>\n<p>Here are the Pods in my test cluster that use the old registry:</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/13FE78CC-1DDD-47D9-B875-EE3FB15F916E/ED8BD697-7BD9-4D58-83FC-833C66606E97_2/dcAQoH7ADPaoupccwi3WFMxt1PkS5ME4zXHHyxjAmdMz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>These are the at-risk Pods. I’ll have to update the container registry used in the Pods.</p>\n<p>When hunting for references to old registry, be sure to include containers that may not be currently running in your cluster.</p>\n<h2 id=\"what-if-i-don%E2%80%99t-control-the-workloads%3F\">What if I don’t control the workloads? <a class=\"direct-link\" href=\"#what-if-i-don%E2%80%99t-control-the-workloads%3F\">#</a></h2>\n<p>One of my colleagues raised an intriguing question. Is there’s a way to handle this change at a cluster level? He had a valid concern. Many large enterprises might not be able to implement this change in time before the community sunsets <code>k8s.gcr.io</code>.</p>\n<p>I work with many customers that manage large Kubernetes clusters, but have little control over the workloads that get deployed into the cluster. Some of these clusters are shared by hundreds of development teams. The burden is on Central Platform Engineering teams to dissipate this information to individual dev teams (who are busy writing code and not checking Kubernetes news!).</p>\n<p>So, what can these teams do to make sure when the old registry finally croaks, they don’t get paged for in the middle of the night for <code>ErrImagePull</code> and <code>ImagePullBackOff</code>errors?</p>\n<p>Turns out you can use containerd to handle this redirection at node level. Let’s find out how.</p>\n<h2 id=\"using-mirrors-in-containerd\">Using mirrors in containerd <a class=\"direct-link\" href=\"#using-mirrors-in-containerd\">#</a></h2>\n<p>Ever since Dockerhub started rate limiting image pulls, many have opted to store images in local registries. Mirrors save network bandwidth, reduce image pull time, and don’t rate-limit.</p>\n<p>You can configure <code>registry.k8s.io</code> as a mirror to <code>k8s.gcr.io</code> in containerd. This configuration will <strong>automatically pull images from <code>registry.k8s.io</code></strong> whenever a Pod uses an image stored in <code>k8s.gcr.io</code>.</p>\n<p>On your worker node, append these lines in the containerd config file at <code>/etc/containerd/config.toml</code>:</p>\n<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token punctuation\">[</span>plugins.<span class=\"token string\">\"io.containerd.grpc.v1.cri\"</span>.registry<span class=\"token punctuation\">]</span><br>   config_path <span class=\"token operator\">=</span> <span class=\"token string\">\"/etc/containerd/certs.d\"</span></code></pre>\n<p>The final file on an Amazon EKS cluster looks like this:</p>\n<pre class=\"language-yaml\"><code class=\"language-yaml\">version = 2<br>root = \"/var/lib/containerd\"<br>state = \"/run/containerd\"<br><br><span class=\"token punctuation\">[</span>grpc<span class=\"token punctuation\">]</span><br>address = \"/run/containerd/containerd.sock\"<br><br><span class=\"token punctuation\">[</span>plugins.\"io.containerd.grpc.v1.cri\".containerd<span class=\"token punctuation\">]</span><br>default_runtime_name = \"runc\"<br><br><span class=\"token punctuation\">[</span>plugins.\"io.containerd.grpc.v1.cri\"<span class=\"token punctuation\">]</span><br>sandbox_image = \"602401143452.dkr.ecr.us<span class=\"token punctuation\">-</span>west<span class=\"token punctuation\">-</span>2.amazonaws.com/eks/pause<span class=\"token punctuation\">:</span>3.5\"<br><br><span class=\"token punctuation\">[</span>plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc<span class=\"token punctuation\">]</span><br>runtime_type = \"io.containerd.runc.v2\"<br><br><span class=\"token punctuation\">[</span>plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options<span class=\"token punctuation\">]</span><br>SystemdCgroup = true<br><br><span class=\"token punctuation\">[</span>plugins.\"io.containerd.grpc.v1.cri\".cni<span class=\"token punctuation\">]</span><br>bin_dir = \"/opt/cni/bin\"<br>conf_dir = \"/etc/cni/net.d\"<br><br><span class=\"token punctuation\">[</span>plugins.\"io.containerd.grpc.v1.cri\".registry<span class=\"token punctuation\">]</span><br>config_path = \"/etc/containerd/certs.d\"</code></pre>\n<p>Next, create a directory called <code>k8s.gcr.io</code> and a <code>hosts.toml</code> file inside it:</p>\n<pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token function\">mkdir</span> -p /etc/containerd/certs.d/k8s.gcr.io<br><br><span class=\"token function\">cat</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token string\">EOF<span class=\"token bash punctuation\"> <span class=\"token operator\">></span> /etc/containerd/certs.d/k8s.gcr.io/hosts.toml</span><br>server = \"https://k8s.gcr.io\"<br><br>[host.\"https://registry.k8s.io\"]<br>capabilities = [\"pull\", \"resolve\"]<br>EOF</span></code></pre>\n<p>Image pull requests to <code>k8s.gcr.io</code> will now be sent to <code>registry.k8s.io</code>.</p>\n<p>Restart containerd and kubelet for the change to take effect.</p>\n<pre class=\"language-bash\"><code class=\"language-bash\">systemctl restart containerd kubelet</code></pre>\n<p>Let’s validate that images are indeed getting pulled from the new registry. I added an entry to my <code>/etc/hosts</code> file to break <code>k8s.gcr.io</code>:</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/13FE78CC-1DDD-47D9-B875-EE3FB15F916E/8AEBA792-CA42-4C8B-9C8D-E34AC55A9847_2/7A4cAKtUBNGVqmUysXRwpW0WGy3cNGz14xxujKlsmc8z/Image.png\" alt=\"Image.png\"></p>\n<p>Containerd can no longer pull an image from <code>k8s.gcr.io</code></p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/13FE78CC-1DDD-47D9-B875-EE3FB15F916E/D382C5B0-437D-44E3-BAA2-E32032FF7E29_2/zmbCw5wl0LyV1TNJdiEQxCnSqKBS3s4IDZWYljKaLvkz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>I can tell <code>ctr</code> to use the mirror by specifying the <code>—hosts-dir</code> parameter:</p>\n<pre class=\"language-bash\"><code class=\"language-bash\">ctr images pull --hosts-dir <span class=\"token string\">\"/etc/containerd/certs.d\"</span> k8s.gcr.io/pause:latest</code></pre>\n<p>This time the operation succeeds.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/13FE78CC-1DDD-47D9-B875-EE3FB15F916E/94C5856D-E54D-414D-86E6-5B7C70A7989B_2/2bTbUm39iI52DAfS4D9GgH1T1LW5pBbWxTHNIjgS2v4z/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>Any Pods I create now onwards will use the new registry even though the manifests reference old registry. Here’s a test using a pause container.</p>\n<pre class=\"language-bash\"><code class=\"language-bash\">kubectl create deployment pause --image k8s.gcr.io/pause</code></pre>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/13FE78CC-1DDD-47D9-B875-EE3FB15F916E/88014DF3-E73E-4A60-B881-64C31B8210B6_2/lnuzXKg7G4RwURvQUxrZwRFuBDljKWpX6m01nVydnxoz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>Perfect! Kubernetes could create Pods even though I blocked <code>k8s.gcr.io</code> on the node.</p>\n<h2 id=\"what%E2%80%99s-the-best-way-to-implement-this-in-production%3F\">What’s the best way to implement this in production? <a class=\"direct-link\" href=\"#what%E2%80%99s-the-best-way-to-implement-this-in-production%3F\">#</a></h2>\n<p>In my little demo, I changed a single node in the cluster. What about the rest of the nodes?</p>\n<p>There are three ways you can use to implement this change on every node in your cluster:</p>\n<ol>\n<li>The easiest way is to use a daemonset to change to containerd config.toml and add hosts.toml file. IBM cloud has shared <a href=\"https://raw.githubusercontent.com/IBM-Cloud/kube-samples/master/containerd-registry-daemonset-example\">this</a> on Github</li>\n<li>You can use <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html\">EC2 user data</a> or <a href=\"https://aws.amazon.com/systems-manager/\">AWS Systems Manager</a> to make this change when a node gets created</li>\n<li>You can <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/eks-ami-build-scripts.html\">create your own AM</a>I</li>\n</ol>\n<h2 id=\"what-if-i-use-docker-as-runtime%3F\">What if I use Docker as runtime? <a class=\"direct-link\" href=\"#what-if-i-use-docker-as-runtime%3F\">#</a></h2>\n<p>Starting Kubernetes version <code>1.24</code>, containerd is the only runtime available in Amazon EKS AMIs. If you have an edge case that requires using Docker, there's still hope.</p>\n<p>Docker also has support for registry mirrors. <a href=\"https://docs.docker.com/registry/recipes/mirror/#configure-the-docker-daemon\">Here’s</a> the documentation page you need.</p>\n<h2 id=\"don%E2%80%99t-rely-on-stop-gaps\">Don’t rely on stop gaps <a class=\"direct-link\" href=\"#don%E2%80%99t-rely-on-stop-gaps\">#</a></h2>\n<p>While the solution included in this post works, I recommend only using as a safety measure. The main reason is that you’ll need to customize the Amazon EKS AMI or create your own AMI to use it.</p>\n<p>You’ll have less operational overhead if you can simply use EKS AMIs as is. The best way to handle this registry deprecation is to update manifests.</p>\n<p>Oh, and by the way, you can also use mirrors to enforce pull through cache.</p>\n",
      "date_published": "2023-04-03T17:00:00-07:00"
    },{
      "id": "https://blog.realvarez.com/posts/scale-eks-mng-to-zero/",
      "url": "https://blog.realvarez.com/posts/scale-eks-mng-to-zero/",
      "title": "Reduce Amazon EKS cost by scaling node groups to zero",
      "content_html": "<p>Amazon EKS just released the support for <a href=\"https://aws.amazon.com/blogs/containers/amazon-eks-now-supports-kubernetes-version-1-24/\">Kubernetes version 1.24</a>. The new version supports a bunch of cool features. My favorite feature in this release is the ability to scale EKS managed node groups to (and from) zero.</p>\n<p>Many customers I engage with have workloads that don’t run continuously. A good example is building software. Software build jobs run when new development teams push new code. Outside of business hours, the supporting infrastructure (like nodes) sits idle. Customers use autoscaling to scale down node groups, but managed node groups required a minimum of 1 node in a node group previously. That’s one node too many, especially when you need beefier and costly nodes with GPUs.</p>\n<p>Scaling down to zero results in significant cost savings in such cases. In my opinion, you wouldn’t want to scale your entire cluster to zero. After all, you’d need some nodes to run Cluster Autoscaler and other shared services like Prometheus, AWS Load Balancer, CoreDNS, etc. You can use EKS on Fargate to run some of these services. But keep in mind that Prometheus requires a block storage, and AWS Fargate doesn’t support Amazon EBS yet.</p>\n<p>You’d want to run a managed node group for your shared services, like Cluster Autoscaler, that run continuously. You can then add another node group for workloads that spawn periodically, and scale that node group to zero.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/1CAE5716-0A06-487B-94D9-ED3A26E55B46/F10EE54C-3121-4A95-A3E8-2084AC07ED39_2/0ePoBv7QUOJphRVgz14AABF7CLN8q6hh0yNumolViQMz/Untitled%20Diagram.drawio.png\" alt=\"Untitled Diagram.drawio.png\"></p>\n<h2 id=\"cluster-autoscaler-managed-node-group-cache\">Cluster Autoscaler Managed Node group cache <a class=\"direct-link\" href=\"#cluster-autoscaler-managed-node-group-cache\">#</a></h2>\n<p>The Kubernetes Cluster Autoscaler project added support for scaling node groups to and from zero in version 0.6.1. However, it only worked if you added <a href=\"https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#how-can-i-scale-a-node-group-to-0\">specific tags</a> to Auto Scaling groups. In other words, after creating a managed node group, you had to find out the associated Auto Scaling group and add Cluster Autoscaler tags yourself.</p>\n<p>Starting Kubernetes version 1.24, you can create node groups (or tag existing node groups) with Cluster Autoscaler tags and Cluster Autoscaler will scale that node group to and from zero.</p>\n<p>To enable scaling to and from zero, the awesome EKS team contributed a feature to the upstream Cluster Autoscaler project. The new feature adds a manage node group cache that holds labels and taints associated with managed node groups. Cluster Autoscaler now uses the EKS <a href=\"https://docs.aws.amazon.com/eks/latest/APIReference/API_DescribeNodegroup.html\"><code>DescribeNodegroup</code></a> API to determine a node's label and taints when there are no nodes in the node group. This allows scaling to and from zero and doesn't require adding Auto Scaling group tags.</p>\n<h2 id=\"cluster-autoscaler-tags-for-scaling-to-zero\">Cluster Autoscaler tags for scaling to zero <a class=\"direct-link\" href=\"#cluster-autoscaler-tags-for-scaling-to-zero\">#</a></h2>\n<p>Before you can start scaling a managed node group to and from zero, you’d need to <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html\">add a few tags</a> to your node group. The tags you attach to your node group will help Cluster Autoscaler determine which node group to scale when a Pod is pending. You can add tags that help Cluster Autoscaler taints, labels, and node group’s resources like <code>WindowsENI</code>, <code>PrivateIPv4Address</code>, etc.</p>\n<p>Labels and taints will tell the Kubernetes scheduler to assign Pods to specific nodes. When those Pods don’t have a node to run on (which will be the case when the node group is scaled to zero), Cluster Autoscaler can determine which node group to scale based on the tags. Let’s explore it using an example.</p>\n<h2 id=\"scaling-a-managed-node-group-from-zero\">Scaling a managed node group from zero <a class=\"direct-link\" href=\"#scaling-a-managed-node-group-from-zero\">#</a></h2>\n<p>You’d need a Kubernetes version 1.24 cluster to follow along. My EKS cluster already has node group, and I have <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/autoscaling.html\">installed Cluster Autoscaler</a> using EKS documentation.</p>\n<p>Cluster Autoscaler needs the permissions to call the EKS <code>DescribeNodegroup</code> API to be able to read a node group's tags. The instructions in EKS documentation currently do not add <code>DescribeNodegroup</code> permissions to the Cluster Autoscaler IAM role.</p>\n<p>The first thing you’d need to do is create an IAM policy that allows the Cluster Autoscaler IAM role to use <code>DescribeNodegroup</code> API.</p>\n<p>Create a policy to allow EKS <code>DescribeNodegroup</code>  API:</p>\n<pre class=\"language-python\"><code class=\"language-python\">cat <span class=\"token operator\">></span> describe<span class=\"token operator\">-</span>nodegroup<span class=\"token punctuation\">.</span>json <span class=\"token operator\">&lt;&lt;</span> EOF<br><span class=\"token punctuation\">{</span><br>    <span class=\"token string\">\"Version\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2012-10-17\"</span><span class=\"token punctuation\">,</span><br>    <span class=\"token string\">\"Statement\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><br>        <span class=\"token punctuation\">{</span><br>            <span class=\"token string\">\"Action\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><br>                <span class=\"token string\">\"eks:DescribeNodegroup\"</span><br>            <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><br>            <span class=\"token string\">\"Effect\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Allow\"</span><span class=\"token punctuation\">,</span><br>            <span class=\"token string\">\"Resource\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"*\"</span><br>        <span class=\"token punctuation\">}</span><br>    <span class=\"token punctuation\">]</span><br><span class=\"token punctuation\">}</span><br>EOF</code></pre>\n<p>Now you need to add this policy to the Cluster Autoscaler IAM Role. Determine the name of the IAM Role attached to the Cluster Autoscaler service account:</p>\n<pre class=\"language-python\"><code class=\"language-python\">CA_IAM_ROLE<span class=\"token operator\">=</span>$<span class=\"token punctuation\">(</span>kubectl <span class=\"token operator\">-</span>n kube<span class=\"token operator\">-</span>system get  sa cluster<span class=\"token operator\">-</span>autoscaler <span class=\"token operator\">-</span>o  jsonpath<span class=\"token operator\">=</span><span class=\"token string\">'{.metadata.annotations.eks\\.amazonaws\\.com/role-arn}'</span> <span class=\"token operator\">|</span> sed <span class=\"token string\">'s|.*/||'</span> <span class=\"token punctuation\">)</span></code></pre>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/1CAE5716-0A06-487B-94D9-ED3A26E55B46/6EF2F66E-E9B7-4B3D-9D75-06400FAE0BF2_2/gI025AVUilKKRF9GfkjpTeq3GmtiWypNeTVa4uE6XYYz/Image.png\" alt=\"Image.png\"></p>\n<p>Then, add the policy you created to the IAM role that Cluster Autoscaler uses:</p>\n<pre class=\"language-python\"><code class=\"language-python\">aws iam put<span class=\"token operator\">-</span>role<span class=\"token operator\">-</span>policy <span class=\"token operator\">-</span><span class=\"token operator\">-</span>role<span class=\"token operator\">-</span>name $CA_IAM_ROLE \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>policy<span class=\"token operator\">-</span>name EKSDescribeNodegroup \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>policy<span class=\"token operator\">-</span>document <span class=\"token builtin\">file</span><span class=\"token punctuation\">:</span><span class=\"token operator\">//</span>describe<span class=\"token operator\">-</span>nodegroup<span class=\"token punctuation\">.</span>json</code></pre>\n<p>Now you can start creating a new node group that you can set to scale to and from zero. Find out the role attached to an existing node group in your cluster. You can use AWS CLI to query that information.</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Store your EKS cluster name in an environment variable</span><br>EKS_CLUSTER<span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>YOUR CLUSTER NAME<span class=\"token operator\">></span><br>AWS_ACCOUNT<span class=\"token operator\">=</span>$<span class=\"token punctuation\">(</span>aws sts get<span class=\"token operator\">-</span>caller<span class=\"token operator\">-</span>identity <span class=\"token operator\">-</span><span class=\"token operator\">-</span>query <span class=\"token string\">'Account'</span> <span class=\"token operator\">-</span><span class=\"token operator\">-</span>output text<span class=\"token punctuation\">)</span><br><br>NODE_ROLE<span class=\"token operator\">=</span>$<span class=\"token punctuation\">(</span>aws eks describe<span class=\"token operator\">-</span>nodegroup \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>cluster<span class=\"token operator\">-</span>name $EKS_CLUSTER \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>nodegroup<span class=\"token operator\">-</span>name <span class=\"token operator\">&lt;</span>YOUR NODE GROUP NAME<span class=\"token operator\">></span> \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>query <span class=\"token string\">'nodegroup.nodeRole'</span> \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>output text<span class=\"token punctuation\">)</span></code></pre>\n<p>You’d also need to provide the subnets for the new node group. You can use <code>describe-nodegroup</code> to find out the subnets attached to an existing node group.</p>\n<p>Create a node group with a label that you will later use to assign Pods to nodes in this node group:</p>\n<pre class=\"language-python\"><code class=\"language-python\">aws eks create<span class=\"token operator\">-</span>nodegroup \\<br> <span class=\"token operator\">-</span><span class=\"token operator\">-</span>cli<span class=\"token operator\">-</span><span class=\"token builtin\">input</span><span class=\"token operator\">-</span>json '<br><span class=\"token punctuation\">{</span><br>  <span class=\"token string\">\"clusterName\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"${EKS_CLUSTER}\"</span><span class=\"token punctuation\">,</span><br>  <span class=\"token string\">\"nodegroupName\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"scale-to-zero\"</span><span class=\"token punctuation\">,</span><br>  <span class=\"token string\">\"scalingConfig\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><br>     <span class=\"token string\">\"minSize\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><span class=\"token punctuation\">,</span><br>     <span class=\"token string\">\"maxSize\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span><br>     <span class=\"token string\">\"desiredSize\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0</span><br>  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span><br>  <span class=\"token string\">\"subnets\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><br>     <span class=\"token string\">\"&lt;subnet-ID1>\"</span><span class=\"token punctuation\">,</span><br>     <span class=\"token string\">\"&lt;subnet-ID2>\"</span><span class=\"token punctuation\">,</span><br>     <span class=\"token string\">\"&lt;subnet-ID3>\"</span><br>   <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><br>  <span class=\"token string\">\"nodeRole\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"${NODE_ROLE}\"</span><span class=\"token punctuation\">,</span><br>  <span class=\"token string\">\"labels\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><br>     <span class=\"token string\">\"app\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"frontend\"</span><br>  <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span><br>  <span class=\"token string\">\"tags\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><br>     <span class=\"token string\">\"k8s.io/cluster-autoscaler/node-template/label/app\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"frontend\"</span><br>  <span class=\"token punctuation\">}</span><br><span class=\"token punctuation\">}</span>'</code></pre>\n<p><em>Replace the subnet IDs to match your environment.</em></p>\n<p>Note that I added a tag <code>k8s.io/cluster-autoscaler/node-template/label/app</code> with value <code>frontend</code>. This is the same as running <code>kubectl label nodes &lt;YOUR NODE NAME&gt; app=frontend</code>. When a node gets created in this node group, it will already have label <code>app=frontend</code>.</p>\n<p>Now that the node group is created, let’s create a pod with a nodeSelector:</p>\n<pre class=\"language-python\"><code class=\"language-python\">cat <span class=\"token operator\">&lt;&lt;</span>EOF <span class=\"token operator\">|</span> kubectl <span class=\"token builtin\">apply</span> <span class=\"token operator\">-</span>f <span class=\"token operator\">-</span><br>apiVersion<span class=\"token punctuation\">:</span> v1<br>kind<span class=\"token punctuation\">:</span> Pod<br>metadata<span class=\"token punctuation\">:</span><br>  name<span class=\"token punctuation\">:</span> nginx<span class=\"token operator\">-</span>test<br>spec<span class=\"token punctuation\">:</span><br>  containers<span class=\"token punctuation\">:</span><br>  <span class=\"token operator\">-</span> name<span class=\"token punctuation\">:</span> nginx<br>    image<span class=\"token punctuation\">:</span> nginx<span class=\"token punctuation\">:</span>latest<br>  nodeSelector<span class=\"token punctuation\">:</span><br>    app<span class=\"token punctuation\">:</span> frontend<br>EOF</code></pre>\n<p>The pod will remain pending for a few minutes. In my case, the pod was in pending state for five minutes.</p>\n<p>In the meantime, you can see Cluster Autoscaler logs:</p>\n<p><code>kubectl -n kube-system logs -f deployment.apps/cluster-autoscaler | grep scale-to-zero</code></p>\n<p>Once Cluster Autoscaler adds a new node, the pod will start running. You can enable <a href=\"https://aws.amazon.com/blogs/containers/automatically-enable-group-metrics-collection-for-amazon-eks-managed-node-groups/\">Auto Scaling group metrics collection</a> to see how your node group scales.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/1CAE5716-0A06-487B-94D9-ED3A26E55B46/D344F40B-8692-4F2F-921C-422DA115E1B7_2/qBfnOkqluRY1yVqZBaMsB6K5xJgA1idkKOxkkfmzx8Az/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>Great! Cluster Autoscaler saw that the test pod was pending, so it scaled the node group from 0.</p>\n<p>Now let’s delete the test pod and verify that the node group goes back to 0:</p>\n<pre class=\"language-python\"><code class=\"language-python\">kubectl delete pods nginx<span class=\"token operator\">-</span>test</code></pre>\n<p>Cluster Autoscaler will notice that the node with app=frontend is not running any pods and scale down the node group (after the cooldown period).</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/1CAE5716-0A06-487B-94D9-ED3A26E55B46/EAD1C890-6DB1-455E-BABB-FAF71E5FD960_2/kDUeT7u0sJs3WqNy7SG8FBvHyHi9ALDkNEsxsuL1jtIz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>Perfect, the node group is back to having 0 nodes.</p>\n<h2 id=\"conclusion\">Conclusion <a class=\"direct-link\" href=\"#conclusion\">#</a></h2>\n<p>Scaling down to zero can result in significant cost savings when you have workloads that don’t run 24x7. With Kubernetes 1.24, all you need to do is tag your node groups with labels, taints, or resources, and Cluster Autoscaler will scale your nodes to and from zero.</p>\n<p>Happy scaling!</p>\n",
      "date_published": "2022-11-15T16:00:00-08:00"
    },{
      "id": "https://blog.realvarez.com/posts/book-review-dawn-of-everything/",
      "url": "https://blog.realvarez.com/posts/book-review-dawn-of-everything/",
      "title": "The Dawn of Everything by David Graeber &amp; David Wengrow",
      "content_html": "<p>The late David Graeber and David Wengrow are the foremost anthropologist and left-wing thinkers of our times. Their decade-long research culminates in an epic retelling of the human history. The Dawn of Everything: A New History of Humanity is an attempt to upend the premise of modern day understanding oh political and social history. The book challenges the notion that private property has shaped our current social landscape. It tries to explore the origins of social inequality and define concepts of personal freedom.</p>\n<p>Besides criticizing the works of Rousseau and Hobbes, the book challenges works by popular intellectuals like Jared Diamond, Steven Pinker, Francis Fukuyama and Yuval Noah Harari in a provocative way. These authors regurgitate the same old myths in spite of the new archeological and anthropological research results.</p>\n<p>The authors disagree that property rights caused humankind to descend into unkind and selfish beings from an original state of egalitarian innocence. They note that hierarchy and domination, and cynical self-interest, have always been the basis of human society.</p>\n<p>The book dispels the myths that prior to becoming capitalists, humans (hunter-gatherers) were savage, politically immature, and egalitarian. Per the authors, human societies before the advent of farming were not confined to small, egalitarian bands. In fact, hunter-gatherers traveled farther distances and mingled with other groups more than we do today.</p>\n<p>A first step towards a more accurate, and hopeful, picture of world history might be to abandon the Garden of Eden once and for all, and simply do away with the notion that for hundreds of thousands of years, everyone on earth shared the same idyllic form of social organization.<br>\nThe core argument of the book is extremely political and challenges the status quo. The book uses anthropological researches about Native Americans, Native Andeans, Egyptians, early Mesopotamians, Eastern Europeans to posit that:</p>\n<ol>\n<li>The 17th century Amerindian society was socially equal much before Europeans started questioning equality in the French society that was intrinsically hierarchical. They impressed Europeans with their eloquence and powers of reasoned argument. “When it came to questions of personal freedom, the equality of men and women, sexual mores or popular sovereignty – or even, for that matter, theories of depth psychology18 – indigenous American attitudes are likely to be far closer to the reader’s own than seventeenth-century European ones.”</li>\n<li>People across Americas, Europe, and Africa changed social structures as seasons changed. Banding together one season and venturing in smaller groups during another. The social and political structure in these societies was more fluid than the contemporary political arrangement.</li>\n<li>Groups across the world chose not to farm. Farming is hard work and humans opted for easier sources of food. The first humans farmed on flood retreat lands, which doesn't require plowing. “Farming, as we can now see, often started out as an economy of deprivation: you only invented it when there was nothing else to be done, which is why it tended to happen first in areas where wild resources were thinnest on the ground.” It took 3000 years for farming to become a standard practice.</li>\n<li>Instead of tilling, threshing, irrigating, and breaking their backs, humans spend their time feasting, dancing, maintaining gardens, practicing botany, playing sports, weaving, hunting, fishing, and gathering nuts. Farming ties farmers to their lands. Non-farmers had the freedom to move as they pleased.</li>\n<li>Unlike in current times, when capitalism and authoritarianism are standard, hunter-gatherers had a diverse social and political setups. Throughout pre-history, there were masses that achieved egalitarianism and self-governance.</li>\n<li>Many early cities, some with up to 25,000 citizens, had no centralized administration. Early societies had the freedom to choose the society they lived in, which is lost in today’s age. “An origin for ‘the state’ has long been sought in such diverse places as ancient Egypt, Inca Peru and Shang China, but what we now regard as states turn out not to be a constant of history at all; not the result of a long evolutionary process that began in the Bronze Age, but rather a confluence of three political forms – sovereignty, administration and charismatic competition – that have different origins.”</li>\n</ol>\n<p>The main takeaway for me was the human history hasn’t progressed in a linear fashion. Capitalism and the modern pseudo-democracy might very well not be the pinnacle of human evolution.<br>\nThis is a very interesting book even though it is plagued by digressions and sometimes excessive polemic. 3.5/5 ⭐️.</p>\n",
      "date_published": "2022-11-11T16:00:00-08:00"
    },{
      "id": "https://blog.realvarez.com/posts/autoscale-metrics-server/",
      "url": "https://blog.realvarez.com/posts/autoscale-metrics-server/",
      "title": "Autoscale Kubernetes Metrics Server",
      "content_html": "<p>Many organizations are happy to standardize their infrastructure platform on Kubernetes. Kubernetes gives engineers a consistent platform across cloud providers and on premises. It abstracts underlying infrastructure so engineers can focus on writing code without having tight-coupling with methods for load balancing, observability, configuration, secrets management, etc.</p>\n<p>I frequently speak with organizations that run their entire workloads in one or two Kubernetes clusters. Effectively, they have moved their entire data centers into Kubernetes clusters.</p>\n<p>Now, Kubernetes is not without its flaws. Especially when operating at scale. Once clusters go beyond hundreds of nodes, nuanced behavior starts showing up. Besides scaling the Kubernetes control plane and data plane, platform teams have to scale Kubernetes components like CoreDNS, core components, and add-ons.</p>\n<p>In this post, I am going to show how to scale the metrics server add-on, so when your cluster scales the Horizontal Pod Autoscaler can reliably scale your workload.</p>\n<h2 id=\"scaling-kubernetes-add-ons\">Scaling Kubernetes add-ons <a class=\"direct-link\" href=\"#scaling-kubernetes-add-ons\">#</a></h2>\n<p>Kubernetes add-ons are software packages that extend the functionality of Kubernetes. Vanilla Kubernetes clusters lack capabilities that most production clusters require. For example, data plane scaling functionality in Kubernetes is provided by the <a href=\"https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler\">Kubernetes Cluster Autoscaler</a>. Metrics server collects Node and Pod metrics. Log aggregators like Fluent Bit and Fluentd allow you to collect Kubernetes application and system logs.</p>\n<p>It is a best practice to deploy these add-ons with resource limits to account for bugs and memory leaks. Requests and limits allow us to control system resource allocated to each Pod. This feature makes it safer to run multiple Pods on a node without worrying about resource contention or oversubscription.</p>\n<p>Add-ons are deployed either as DaemonSets or Deployments. As a cluster scales, DaemonSets scale automatically as they run once per node. However, add-ons deployed as Deployments do not scale automatically because they are unaware of the size of the cluster’s scale.</p>\n<p>As the cluster scales, add-ons such as <a href=\"https://github.com/kubernetes-sigs/metrics-server\">metrics-server</a> and <a href=\"https://github.com/kubernetes/kube-state-metrics\">kube-state-metrics</a> have to hold more data in memory. The default resource requests on the metrics-server are sized for clusters of up to 100 nodes. In clusters larger than that, the metrics-server can run out of memory, which breaks the Horizontal Pod Autoscaler.</p>\n<p>As a result, operators have to scale add-ons, such as the metrics server, vertically as the cluster scales. <a href=\"https://github.com/kubernetes/autoscaler/tree/master/addon-resizer\">Addon-resizer</a> is an open source tool you can use to scale Deployments in proportion to the data plane. While the Kubernetes <a href=\"https://github.com/kubernetes-sigs/cluster-proportional-autoscaler\">Cluster Proportional Autoscaler</a> scales Deployments horizontally, the addon-resizer scales Deployments vertically.</p>\n<p>Some cloud providers use addon-resizer to scale the metrics-server add-on. Amazon EKS currently doesn't automatically scale metrics-server. I am going to run addon-resizer to autoscale the metrics-server Deployment in an EKS cluster.</p>\n<h2 id=\"addon-resizer\">Addon-resizer <a class=\"direct-link\" href=\"#addon-resizer\">#</a></h2>\n<p>Addon-resizer is a container that vertically scales a Deployment based on the number of nodes in your cluster. It scales Deployments linearly as the cluster’s data plane grows and shrinks.</p>\n<p>The container monitors your cluster periodically and increases or decreases the requests and limits of a Deployment in proportion to the number of nodes. Vertical scaling implies that <strong>addon-resizer will recreate the Pods</strong> with newer resource limits.</p>\n<p>At the core of addon-resizer lies the *nanny *program.</p>\n<pre><code>Usage of ./pod_nanny:\n      --acceptance-offset=20: A number from range 0-100. The dependent's resources are rewritten when they deviate from expected by a percentage that is higher than this threshold. Can't be lower than recommendation-offset.\n      --alsologtostderr[=false]: log to standard error as well as files\n      --container=&quot;pod-nanny&quot;: The name of the container to watch. This defaults to the nanny itself.\n      --cpu=&quot;MISSING&quot;: The base CPU resource requirement.\n      --deployment=&quot;&quot;: The name of the deployment being monitored. This is required.\n      --extra-cpu=&quot;0&quot;: The amount of CPU to add per node.\n      --extra-memory=&quot;0Mi&quot;: The amount of memory to add per node.\n      --extra-storage=&quot;0Gi&quot;: The amount of storage to add per node.\n      --log-flush-frequency=5s: Maximum number of seconds between log flushes\n      --log_backtrace_at=:0: when logging hits line file:N, emit a stack trace\n      --log_dir=&quot;&quot;: If non-empty, write log files in this directory\n      --logtostderr[=true]: log to standard error instead of files\n      --memory=&quot;MISSING&quot;: The base memory resource requirement.\n      --namespace=&quot;&quot;: The namespace of the ward. This defaults to the nanny pod's own namespace.\n      --pod=&quot;&quot;: The name of the pod to watch. This defaults to the nanny's own pod.\n      --poll-period=10000: The time, in milliseconds, to poll the dependent container.\n      --recommendation-offset=10: A number from range 0-100. When the dependent's resources are rewritten, they are set to the closer end of the range defined by this percentage threshold.\n      --stderrthreshold=2: logs at or above this threshold go to stderr\n      --storage=&quot;MISSING&quot;: The base storage resource requirement.\n      --v=0: log level for V logs\n      --vmodule=: comma-separated list of pattern=N settings for file-filtered logging\n</code></pre>\n<p>The nanny program takes the base CPU and memory and adds extra resources per node. Here’s the formula it uses:</p>\n<pre><code>Base  CPU + (Extra CPU * Nodes)\n</code></pre>\n<p>Let’s say we allocate 100m CPU and 200Mi memory to a container in our cluster. We configure addon-resizer to add 1m CPU and 2Mi memory per node. When the cluster scales to 75 nodes, addon-resizer will scale the target container using the formula below:</p>\n<pre><code>100m+(1m*75) = 175m\n</code></pre>\n<p>It will also increase memory:</p>\n<pre><code>200Mi + (2Mi*75)= 350Mi\n</code></pre>\n<h2 id=\"scale-metrics-server\">Scale metrics-server <a class=\"direct-link\" href=\"#scale-metrics-server\">#</a></h2>\n<p>The first question you may have is when should you scale metrics-server. The default resource configuration in metrics-server Deployment is recommended for clusters of up to 100 nodes. Beyond that you may notice the metrics-server restarting frequently (as it gets killed by Kubernetes Out of Memory killer).</p>\n<p>When metrics-server needs more resources than allocated <code>kubectl top nodes</code> and <code>kubectl top pods</code> will fail. You may get the following error message:</p>\n<p><code>unable to get metrics for resource cpu: unable to fetch metrics from resource metrics API: the server is currently unable to handle the request (get pods.metrics.k8s.io)</code></p>\n<p>Also, the Horizontal Pod Autoscaler may stop working. If you run <code>kubectl get apiservices v1beta1.metrics.k8s.io</code>, you may get the following message:</p>\n<pre><code>NAME                     SERVICE                      AVAILABLE                      AGE\nv1beta1.metrics.k8s.io   kube-system/metrics-server   False (FailedDiscoveryCheck)   12m\n</code></pre>\n<h2 id=\"deploy-addon-resizer\">Deploy addon-resizer <a class=\"direct-link\" href=\"#deploy-addon-resizer\">#</a></h2>\n<p>The addon-resizer container can run in its own Pod or as a sidecar. We’re going to deploy the container as a sidecar in the metrics-server Deployment.</p>\n<p>The metrics server defaults to 100m CPU and 200Mi memory. Get the current limits:</p>\n<pre><code>kubectl -n kube-system get \\\n  deployments metrics-server \\\n  -o jsonpath='{.spec.template.spec.containers[].resources}'\n</code></pre>\n<p>Here’s the output from my cluster:</p>\n<pre><code>{&quot;requests&quot;:{&quot;cpu&quot;:&quot;100m&quot;,&quot;memory&quot;:&quot;200Mi&quot;}}\n</code></pre>\n<p>My cluster currently has 5 nodes. I’ll configure the addon-resizer to scale the metrics-server Deployment vertically by adding 1m CPU per node in addition to the base CPU which is set to 20m. The base memory is 15Mi, and addon-resizer will increase metrics-server memory by 2Mi per node. I took these values from addon-resizer recommendations.</p>\n<p>Deploy the manifest to create a ClusterRole, Role, and ClusterRoleBinding that gives the metrics-server service account the permissions to patch the metrics-server Deployment:</p>\n<pre><code>cat &lt;&lt;EOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: eks:metrics-server-nanny\n  labels:\n    k8s-app: metrics-server\nrules:\n- nonResourceURLs:\n  - /metrics\n  verbs:\n  - get\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: eks:metrics-server-nanny\n  labels:\n    k8s-app: metrics-server\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: eks:metrics-server-nanny\nsubjects:\n  - kind: ServiceAccount\n    name: metrics-server\n    namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: metrics-server-nanny\n  namespace: kube-system\n  labels:\n    k8s-app: metrics-server\nrules:\n- apiGroups:\n  - &quot;&quot;\n  resources:\n  - pods\n  verbs:\n  - get\n- apiGroups:\n  - apps\n  resources:\n  - deployments\n  resourceNames:\n  - metrics-server\n  verbs:\n  - get\n  - patch\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: metrics-server-nanny\n  namespace: kube-system\n  labels:\n    k8s-app: metrics-server\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: Role\n  name: metrics-server-nanny\nsubjects:\n  - kind: ServiceAccount\n    name: metrics-server\n    namespace: kube-system\nEOF\n</code></pre>\n<p>Create a patch file to add the nanny container to the metrics-server Deployment.</p>\n<pre><code>cat &gt; metrics-server-addon-patch.yaml &lt;&lt; EOF\nspec:\n  template:\n    spec:\n      containers:\n      - name: metrics-server-nanny\n          image: registry.k8s.io/autoscaling/addon-resizer:1.8.14\n          resources:\n            limits:\n              cpu: 40m\n              memory: 25Mi\n            requests:\n              cpu: 40m\n              memory: 25Mi\n          env:\n            - name: MY_POD_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.name\n            - name: MY_POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  fieldPath: metadata.namespace\n          command:\n            - /pod_nanny\n            - --cpu=20m\n            - --extra-cpu=1m\n            - --memory=15Mi\n            - --extra-memory=2Mi\n            - --threshold=5\n            - --deployment=metrics-server\n            - --container=metrics-server\n            - --poll-period=30000\n            - --estimator=exponential\n            - --minClusterSize=10\n            - --use-metrics=true\nEOF\n\nkubectl -n kube-system patch deployments metrics-server --patch-file metrics-server-addon-patch.yaml\n</code></pre>\n<p>If you install the metrics-server as documented in Amazon EKS documentation, it requests 100m CPU and 200Mi memory. After deploying the patch above, the metrics server requests set to 40m CPU and 15Mi memory. As you add more nodes, the nanny will automatically adjust the requests and limits for the metrics-server container.</p>\n<p>I scaled my cluster to 15 nodes and the addon-resizer configured metrics-server requests to 35m CPU and 45Mi memory.</p>\n<pre><code>20baseCPU+(15nodes*1extraCPU) = 35m\n\n</code></pre>\n<p>Memory calculation</p>\n<pre><code>15baseMemory+(15nodes*2extraMemory) = 45Mi\n\n</code></pre>\n<p>Addon-resizer calculates the resources reservation for the metrics-server container and  restarts the container automatically.</p>\n<h2 id=\"what-about-scaling-metrics-server-horizontally%3F\">What about scaling metrics server horizontally? <a class=\"direct-link\" href=\"#what-about-scaling-metrics-server-horizontally%3F\">#</a></h2>\n<p>While you can run metrics server in high-availability mode, its main purpose is ensuring that if one of the metrics server Pods terminate, the other one can still serve requests.</p>\n<p>Running two instances of metrics server doesn’t provide any further benefits. Both instances will scrape all nodes to collect metrics, but only one instance will be actively serving metrics API.</p>\n<h2 id=\"conclusion\">Conclusion <a class=\"direct-link\" href=\"#conclusion\">#</a></h2>\n<p>The Amazon EKS documentation currently documents steps to deploy metrics-server in static configuration. You can use addon-resizer to autoscale the metrics-server based on the number of nodes in your cluster.</p>\n",
      "date_published": "2022-11-02T17:00:00-07:00"
    },{
      "id": "https://blog.realvarez.com/posts/estargz/",
      "url": "https://blog.realvarez.com/posts/estargz/",
      "title": "Using eStargz to reduce container startup time on Amazon EKS",
      "content_html": "<p>A container image bundles executable code, library, and configuration. Images contain everything an application needs to run. It is a best practice to exclude any file that’s unnecessary for the application packaged in the image. A smaller image means that when you create a container, the container runtime (dockerd or containerd) will have to download fewer bits from the container registry, which will result in faster startup time.</p>\n<p>There are cases when the container image becomes significantly large (&gt;500 MB). A common scenario is machine learning workloads. ML workload containers usually package model data necessary for the application. The image size for these containers can easily span in to multiple GBs. As a result, these applications have a slower startup time when the runtime has to pull the image. In fact, <a href=\"https://www.usenix.org/conference/fast16/technical-sessions/presentation/harter\">research</a> shows that pulling packages accounts for 76% of container start time, but only 6.4% of that data is read.</p>\n<h2 id=\"lazy-pulling\">Lazy-pulling <a class=\"direct-link\" href=\"#lazy-pulling\">#</a></h2>\n<p>There are two open source projects designed to improve container startup time. <a href=\"https://github.com/containerd/stargz-snapshotter\">Stargz</a> and <a href=\"https://github.com/awslabs/soci-snapshotter\">SOCI</a> are containerd plugins that reduce the cold start time by providing a way to run containers without downloading the entire image. They introduce the concept of <em>lazy pulling</em>, a technique that allows the runtime to download the bits from the container registry as needed.</p>\n<p>Using lazy pulling significantly reduces the application startup time. eStargz is a lazily-pullable image format that is compatible with <a href=\"https://github.com/opencontainers/runtime-spec\">OCI runtimes</a> and standard container registries like DockerHub, GitHub Container Registry.</p>\n<h2 id=\"estargz\">eStargz <a class=\"direct-link\" href=\"#estargz\">#</a></h2>\n<p>The eStargz image format is based on stargz image format by Container Registry Filesystem (CRFS) open source project. <strong>CRFS</strong> is a read-only FUSE filesystem that lets you mount a container image, served directly from a container registry, without pulling it all locally first. The project introduces <strong>S</strong>eekable tar.gz format, which makes tar.gz files seekable using an index.</p>\n<h2 id=\"stargz-snapshotter-plugin\">Stargz Snapshotter plugin <a class=\"direct-link\" href=\"#stargz-snapshotter-plugin\">#</a></h2>\n<p>Stargz snapshotter is implemented as a <a href=\"https://github.com/containerd/containerd/blob/04985039cede6aafbb7dfb3206c9c4d04e2f924d/PLUGINS.md#proxy-plugins\">proxy plugin</a> daemon (<code>containerd-stargz-grpc</code>) for containerd. When containerd starts a container, it queries the rootfs snapshots to stargz snapshotter daemon through a unix socket. This snapshotter remotely mounts queried eStargz layers from registries on the node and provides these mount points as remote snapshots to containerd. The plugin uses FUSE to mount eStargz layers directly from the container registry.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/28146E5F-3F27-4D41-94B7-CF6EF7615505/C70CF5ED-93B1-43E2-B0C2-41D09499BBC8_2/kxUcYlMPhkl9lEW9PWLWDQpsZcldhni1S81OJseSGZgz/Image.tiff\" alt=\"Image.tiff\"></p>\n<h2 id=\"running-estargz-images-on-amazon-eks\">Running eStargz images on Amazon EKS <a class=\"direct-link\" href=\"#running-estargz-images-on-amazon-eks\">#</a></h2>\n<p>eStargz images are a little different from the images you’d build using <code>docker build</code>. In order to create an image that supports lazy pulling, you'll need an eStargz-aware image builder or a converter.</p>\n<p>I am going to build my eStargz image using nerdctl, which is an eStargz-aware image builder. Since image size is not an issue, I will use Debian Jessie as the base image to demo. To make the image size artificially large, I will include twenty 50 MB files.</p>\n<p>Lets generate large files containing random text:</p>\n<pre class=\"language-python\"><code class=\"language-python\">mkdir files<br><span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token punctuation\">{</span><span class=\"token number\">0.</span><span class=\"token number\">.20</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">;</span> do base64 <span class=\"token operator\">/</span>dev<span class=\"token operator\">/</span>urandom <span class=\"token operator\">|</span> head <span class=\"token operator\">-</span>c <span class=\"token number\">50000000</span> <span class=\"token operator\">></span> files<span class=\"token operator\">/</span><span class=\"token builtin\">file</span>$<span class=\"token punctuation\">{</span>i<span class=\"token punctuation\">}</span><span class=\"token punctuation\">.</span>txt<span class=\"token punctuation\">;</span> done</code></pre>\n<p>Create a DockerFile:</p>\n<pre class=\"language-python\"><code class=\"language-python\">cat <span class=\"token operator\">></span> Dockerfile <span class=\"token operator\">&lt;&lt;</span>EOF<br>FROM debian<span class=\"token punctuation\">:</span>jessie<br>RUN apt<span class=\"token operator\">-</span>get update <span class=\"token operator\">&amp;</span><span class=\"token operator\">&amp;</span> apt<span class=\"token operator\">-</span>get install <span class=\"token operator\">-</span>y \\<br>    vim<br>COPY files <span class=\"token punctuation\">.</span><br><br>EOF</code></pre>\n<p>I am going to store my image in Amazon ECR. I’ll create an ECR repository:</p>\n<pre class=\"language-python\"><code class=\"language-python\">ECR_URI<span class=\"token operator\">=</span>$<span class=\"token punctuation\">(</span>aws ecr create<span class=\"token operator\">-</span>repository \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>repository<span class=\"token operator\">-</span>name estargz<span class=\"token operator\">-</span>demo \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>query <span class=\"token string\">'repository.repositoryUri'</span> \\<br>  <span class=\"token operator\">-</span><span class=\"token operator\">-</span>output text<span class=\"token punctuation\">)</span></code></pre>\n<p>Use nerdctl to create container image:</p>\n<pre class=\"language-python\"><code class=\"language-python\">sudo nerdctl build <span class=\"token operator\">-</span>t $<span class=\"token punctuation\">{</span>ECR_URI<span class=\"token punctuation\">}</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span> <span class=\"token punctuation\">.</span></code></pre>\n<p>The image is not in eStargz formatted right now, I’ll have to convert it:</p>\n<pre class=\"language-python\"><code class=\"language-python\">nerdctl image convert <span class=\"token operator\">-</span><span class=\"token operator\">-</span>estargz <span class=\"token operator\">-</span><span class=\"token operator\">-</span>oci \\<br>  $<span class=\"token punctuation\">{</span>ECR_URI<span class=\"token punctuation\">}</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span> $<span class=\"token punctuation\">{</span>ECR_URI<span class=\"token punctuation\">}</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>esgz</code></pre>\n<p>The resulting images:</p>\n<pre class=\"language-python\"><code class=\"language-python\">nerdctl images<br>REPOSITORY                                                   TAG       IMAGE ID        CREATED           PLATFORM       SIZE       BLOB SIZE<br>account<span class=\"token punctuation\">.</span>dkr<span class=\"token punctuation\">.</span>ecr<span class=\"token punctuation\">.</span>us<span class=\"token operator\">-</span>west<span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">.</span>amazonaws<span class=\"token punctuation\">.</span>com<span class=\"token operator\">/</span>estargz<span class=\"token operator\">-</span>demo    <span class=\"token number\">1</span>         798b85a131ed    <span class=\"token number\">31</span> minutes ago    linux<span class=\"token operator\">/</span>amd64    <span class=\"token number\">1.2</span> GiB    <span class=\"token number\">828.8</span> MiB<br>account<span class=\"token punctuation\">.</span>dkr<span class=\"token punctuation\">.</span>ecr<span class=\"token punctuation\">.</span>us<span class=\"token operator\">-</span>west<span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">.</span>amazonaws<span class=\"token punctuation\">.</span>com<span class=\"token operator\">/</span>estargz<span class=\"token operator\">-</span>demo    <span class=\"token number\">1</span><span class=\"token operator\">-</span>esgz    81b0ffd2a4a3    <span class=\"token number\">36</span> seconds ago    linux<span class=\"token operator\">/</span>amd64    <span class=\"token number\">0.0</span> B      <span class=\"token number\">832.3</span> MiB</code></pre>\n<p>Login to ECR and push the image to ECR:</p>\n<pre class=\"language-python\"><code class=\"language-python\">aws ecr get<span class=\"token operator\">-</span>login<span class=\"token operator\">-</span>password <span class=\"token operator\">|</span> sudo nerdctl login \\<br>   <span class=\"token operator\">-</span><span class=\"token operator\">-</span>username AWS \\<br>   <span class=\"token operator\">-</span><span class=\"token operator\">-</span>password<span class=\"token operator\">-</span>stdin \\<br>   $ECR_URI<br>nerdctl push $<span class=\"token punctuation\">{</span>ECR_URI<span class=\"token punctuation\">}</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>esgz</code></pre>\n<p>The image is now available in ECR and I can start running it in my EKS cluster.</p>\n<h2 id=\"create-a-managed-node-group-that-uses-containerd\">Create a managed node group that uses containerd <a class=\"direct-link\" href=\"#create-a-managed-node-group-that-uses-containerd\">#</a></h2>\n<p>EKS nodes currently don’t enable containerd by default. I’ll create a node group that uses containerd.</p>\n<p>Create environment variables for AWS Region and EKS cluster name:</p>\n<pre class=\"language-python\"><code class=\"language-python\">AWS_REGION<span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>Your AWS Region<span class=\"token operator\">></span><br>CLUSTER_NAME<span class=\"token operator\">=</span><span class=\"token operator\">&lt;</span>Your EKS cluster's name<span class=\"token operator\">></span></code></pre>\n<p>First, I need to retrieve the id of the EKS optimized AMI in my region:</p>\n<pre class=\"language-python\"><code class=\"language-python\">AMI_ID<span class=\"token operator\">=</span>$<span class=\"token punctuation\">(</span>aws ssm get<span class=\"token operator\">-</span>parameter <span class=\"token operator\">-</span><span class=\"token operator\">-</span>name <span class=\"token operator\">/</span>aws<span class=\"token operator\">/</span>service<span class=\"token operator\">/</span>eks<span class=\"token operator\">/</span>optimized<span class=\"token operator\">-</span>ami<span class=\"token operator\">/</span><span class=\"token number\">1.23</span><span class=\"token operator\">/</span>amazon<span class=\"token operator\">-</span>linux<span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token operator\">/</span>recommended<span class=\"token operator\">/</span>image_id <span class=\"token operator\">-</span><span class=\"token operator\">-</span>region us<span class=\"token operator\">-</span>west<span class=\"token operator\">-</span><span class=\"token number\">2</span> <span class=\"token operator\">-</span><span class=\"token operator\">-</span>query <span class=\"token string\">\"Parameter.Value\"</span> <span class=\"token operator\">-</span><span class=\"token operator\">-</span>output text<span class=\"token punctuation\">)</span></code></pre>\n<pre class=\"language-python\"><code class=\"language-python\">cat <span class=\"token operator\">></span> containerd<span class=\"token operator\">-</span>mng<span class=\"token punctuation\">.</span>yaml <span class=\"token operator\">&lt;&lt;</span>EOF<br>apiVersion<span class=\"token punctuation\">:</span> eksctl<span class=\"token punctuation\">.</span>io<span class=\"token operator\">/</span>v1alpha5<br>kind<span class=\"token punctuation\">:</span> ClusterConfig<br><br>metadata<span class=\"token punctuation\">:</span><br>  name<span class=\"token punctuation\">:</span> $CLUSTER_NAME<br>  region<span class=\"token punctuation\">:</span> $AWS_REGION<br><br>managedNodeGroups<span class=\"token punctuation\">:</span><br>  <span class=\"token operator\">-</span> name<span class=\"token punctuation\">:</span> containerd<span class=\"token operator\">-</span>mng<br>    minSize<span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><br>    maxSize<span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><br>    desiredCapacity<span class=\"token punctuation\">:</span> <span class=\"token number\">1</span><br>    instanceType<span class=\"token punctuation\">:</span> m5<span class=\"token punctuation\">.</span>xlarge<br>    ami<span class=\"token punctuation\">:</span> $AMI_ID<br>    overrideBootstrapCommand<span class=\"token punctuation\">:</span> <span class=\"token operator\">|</span><br>      <span class=\"token comment\">#!/bin/bash</span><br>      <span class=\"token operator\">/</span>etc<span class=\"token operator\">/</span>eks<span class=\"token operator\">/</span>bootstrap<span class=\"token punctuation\">.</span>sh Socrates <span class=\"token operator\">-</span><span class=\"token operator\">-</span>container<span class=\"token operator\">-</span>runtime containerd<br>    <br>EOF</code></pre>\n<h2 id=\"preparing-eks-nodes-to-use-estargz\">Preparing EKS nodes to use eStargz <a class=\"direct-link\" href=\"#preparing-eks-nodes-to-use-estargz\">#</a></h2>\n<p>Next, I need to install eStargz snapshotter plugin on my worker node. I use AWS Systems Manager on my nodes, so I will connect to the containerd node.</p>\n<pre class=\"language-python\"><code class=\"language-python\">aws ssm start<span class=\"token operator\">-</span>session <span class=\"token operator\">-</span><span class=\"token operator\">-</span>target <span class=\"token operator\">&lt;</span>Instance ID of the worker node<span class=\"token operator\">></span></code></pre>\n<p>Connect to the node (using ssh or Systems Manager) and back up the current containerd config file (/etc/containerd/config.toml) and replace it with:</p>\n<pre class=\"language-python\"><code class=\"language-python\">sudo mv <span class=\"token operator\">/</span>etc<span class=\"token operator\">/</span>containerd<span class=\"token operator\">/</span>config<span class=\"token punctuation\">.</span>toml <span class=\"token operator\">/</span>etc<span class=\"token operator\">/</span>containerd<span class=\"token operator\">/</span>config<span class=\"token punctuation\">.</span>toml<span class=\"token punctuation\">.</span>bak<br>cat <span class=\"token operator\">></span> config<span class=\"token punctuation\">.</span>toml <span class=\"token operator\">&lt;&lt;</span>EOF<br>version <span class=\"token operator\">=</span> <span class=\"token number\">2</span><br>root <span class=\"token operator\">=</span> <span class=\"token string\">\"/var/lib/containerd\"</span><br>state <span class=\"token operator\">=</span> <span class=\"token string\">\"/run/containerd\"</span><br><br><span class=\"token punctuation\">[</span>grpc<span class=\"token punctuation\">]</span><br>address <span class=\"token operator\">=</span> <span class=\"token string\">\"/run/containerd/containerd.sock\"</span><br><br><span class=\"token punctuation\">[</span>plugins<span class=\"token punctuation\">.</span><span class=\"token string\">\"io.containerd.grpc.v1.cri\"</span><span class=\"token punctuation\">.</span>containerd<span class=\"token punctuation\">]</span><br>default_runtime_name <span class=\"token operator\">=</span> <span class=\"token string\">\"runc\"</span><br>snapshotter <span class=\"token operator\">=</span> <span class=\"token string\">\"stargz\"</span><br>disable_snapshot_annotations <span class=\"token operator\">=</span> false<br><br><span class=\"token punctuation\">[</span>plugins<span class=\"token punctuation\">.</span><span class=\"token string\">\"io.containerd.grpc.v1.cri\"</span><span class=\"token punctuation\">]</span><br>sandbox_image <span class=\"token operator\">=</span> <span class=\"token string\">\"602401143452.dkr.ecr.us-west-2.amazonaws.com/eks/pause:3.5\"</span><br><br><span class=\"token punctuation\">[</span>plugins<span class=\"token punctuation\">.</span><span class=\"token string\">\"io.containerd.grpc.v1.cri\"</span><span class=\"token punctuation\">.</span>containerd<span class=\"token punctuation\">.</span>runtimes<span class=\"token punctuation\">.</span>runc<span class=\"token punctuation\">]</span><br>runtime_type <span class=\"token operator\">=</span> <span class=\"token string\">\"io.containerd.runc.v2\"</span><br><br><span class=\"token punctuation\">[</span>plugins<span class=\"token punctuation\">.</span><span class=\"token string\">\"io.containerd.grpc.v1.cri\"</span><span class=\"token punctuation\">.</span>containerd<span class=\"token punctuation\">.</span>runtimes<span class=\"token punctuation\">.</span>runc<span class=\"token punctuation\">.</span>options<span class=\"token punctuation\">]</span><br>SystemdCgroup <span class=\"token operator\">=</span> true<br><br><span class=\"token punctuation\">[</span>plugins<span class=\"token punctuation\">.</span><span class=\"token string\">\"io.containerd.grpc.v1.cri\"</span><span class=\"token punctuation\">.</span>cni<span class=\"token punctuation\">]</span><br>bin_dir <span class=\"token operator\">=</span> <span class=\"token string\">\"/opt/cni/bin\"</span><br>conf_dir <span class=\"token operator\">=</span> <span class=\"token string\">\"/etc/cni/net.d\"</span><br><br><span class=\"token punctuation\">[</span>proxy_plugins<span class=\"token punctuation\">]</span><br>  <span class=\"token punctuation\">[</span>proxy_plugins<span class=\"token punctuation\">.</span>stargz<span class=\"token punctuation\">]</span><br>    <span class=\"token builtin\">type</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"snapshot\"</span><br>    address <span class=\"token operator\">=</span> <span class=\"token string\">\"/run/containerd-stargz-grpc/containerd-stargz-grpc.sock\"</span><br>EOF<br>sudo mv config<span class=\"token punctuation\">.</span>toml <span class=\"token operator\">/</span>etc<span class=\"token operator\">/</span>containerd<span class=\"token operator\">/</span>config<span class=\"token punctuation\">.</span>toml</code></pre>\n<p>Install FUSE:</p>\n<pre class=\"language-python\"><code class=\"language-python\">sudo yum install fuse <span class=\"token operator\">-</span>y<br>sudo modprobe fuse<br>sudo bash <span class=\"token operator\">-</span>c <span class=\"token string\">'echo \"fuse\" > /etc/modules-load.d/fuse.conf'</span></code></pre>\n<p>Install the snapshotter from its <a href=\"https://github.com/containerd/stargz-snapshotter/releases\">GitHub</a> repository:</p>\n<pre class=\"language-python\"><code class=\"language-python\">wget https<span class=\"token punctuation\">:</span><span class=\"token operator\">//</span>github<span class=\"token punctuation\">.</span>com<span class=\"token operator\">/</span>containerd<span class=\"token operator\">/</span>stargz<span class=\"token operator\">-</span>snapshotter<span class=\"token operator\">/</span>releases<span class=\"token operator\">/</span>download<span class=\"token operator\">/</span>v0<span class=\"token punctuation\">.</span><span class=\"token number\">12.1</span><span class=\"token operator\">/</span>stargz<span class=\"token operator\">-</span>snapshotter<span class=\"token operator\">-</span>v0<span class=\"token punctuation\">.</span><span class=\"token number\">12.1</span><span class=\"token operator\">-</span>linux<span class=\"token operator\">-</span>amd64<span class=\"token punctuation\">.</span>tar<span class=\"token punctuation\">.</span>gz<br>sudo tar xvzf stargz<span class=\"token operator\">-</span>snapshotter<span class=\"token operator\">-</span>v0<span class=\"token punctuation\">.</span><span class=\"token number\">12.1</span><span class=\"token operator\">-</span>linux<span class=\"token operator\">-</span>amd64<span class=\"token punctuation\">.</span>tar<span class=\"token punctuation\">.</span>gz <span class=\"token operator\">-</span>C <span class=\"token operator\">/</span>usr<span class=\"token operator\">/</span>local<span class=\"token operator\">/</span><span class=\"token builtin\">bin</span><br>sudo wget <span class=\"token operator\">-</span>O <span class=\"token operator\">/</span>etc<span class=\"token operator\">/</span>systemd<span class=\"token operator\">/</span>system<span class=\"token operator\">/</span>stargz<span class=\"token operator\">-</span>snapshotter<span class=\"token punctuation\">.</span>service https<span class=\"token punctuation\">:</span><span class=\"token operator\">//</span>raw<span class=\"token punctuation\">.</span>githubusercontent<span class=\"token punctuation\">.</span>com<span class=\"token operator\">/</span>containerd<span class=\"token operator\">/</span>stargz<span class=\"token operator\">-</span>snapshotter<span class=\"token operator\">/</span>main<span class=\"token operator\">/</span>script<span class=\"token operator\">/</span>config<span class=\"token operator\">/</span>etc<span class=\"token operator\">/</span>systemd<span class=\"token operator\">/</span>system<span class=\"token operator\">/</span>stargz<span class=\"token operator\">-</span>snapshotter<span class=\"token punctuation\">.</span>service<br>sudo systemctl enable <span class=\"token operator\">-</span><span class=\"token operator\">-</span>now stargz<span class=\"token operator\">-</span>snapshotter</code></pre>\n<p>Finally, restart the containerd and kubelet:</p>\n<pre class=\"language-python\"><code class=\"language-python\">sudo systemctl restart containerd<br>sudo systemctl restart kubelet</code></pre>\n<h2 id=\"test-lazy-pulling\">Test lazy-pulling <a class=\"direct-link\" href=\"#test-lazy-pulling\">#</a></h2>\n<p>I will now run the pod using my eStargz formatted image. Create a manifest for a new pod and replace the node name with the newly created node:</p>\n<pre class=\"language-python\"><code class=\"language-python\">cat <span class=\"token operator\">></span> estargz<span class=\"token operator\">-</span>pod<span class=\"token punctuation\">.</span>yaml <span class=\"token operator\">&lt;&lt;</span>EOF<br>apiVersion<span class=\"token punctuation\">:</span> v1<br>kind<span class=\"token punctuation\">:</span> Pod<br>metadata<span class=\"token punctuation\">:</span><br>  name<span class=\"token punctuation\">:</span> stargz<span class=\"token operator\">-</span>demo<br>spec<span class=\"token punctuation\">:</span><br>  containers<span class=\"token punctuation\">:</span><br>  <span class=\"token operator\">-</span> name<span class=\"token punctuation\">:</span> stargz<span class=\"token operator\">-</span>demo<br>    image<span class=\"token punctuation\">:</span> $<span class=\"token punctuation\">{</span>ECR_URI<span class=\"token punctuation\">}</span><span class=\"token punctuation\">:</span><span class=\"token number\">1</span><span class=\"token operator\">-</span>esgz<br>    command<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span> <span class=\"token string\">\"/bin/bash\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"-c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"--\"</span> <span class=\"token punctuation\">]</span><br>    args<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span> <span class=\"token string\">\"while true; do sleep 30; done;\"</span> <span class=\"token punctuation\">]</span><br>  nodeName<span class=\"token punctuation\">:</span> ip<span class=\"token operator\">-</span><span class=\"token number\">192</span><span class=\"token operator\">-</span><span class=\"token number\">168</span><span class=\"token operator\">-</span><span class=\"token number\">32</span><span class=\"token operator\">-</span><span class=\"token number\">236</span><span class=\"token punctuation\">.</span>us<span class=\"token operator\">-</span>west<span class=\"token operator\">-</span><span class=\"token number\">2</span><span class=\"token punctuation\">.</span>compute<span class=\"token punctuation\">.</span>internal<br>EOF</code></pre>\n<p>The pod started in 2 seconds:</p>\n<pre class=\"language-python\"><code class=\"language-python\">k get pods<br>NAME                            READY   STATUS        RESTARTS      AGE<br>stargz<span class=\"token operator\">-</span>demo                     <span class=\"token number\">1</span><span class=\"token operator\">/</span><span class=\"token number\">1</span>     Running       <span class=\"token number\">0</span>             2s</code></pre>\n<p>To compare, I ran the same pod on another node that didn’t use containerd. It took 45 seconds to start the same image. That’s a lot of improvement in pod startup time!!</p>\n<p>Image pull time <em>without</em> eStargz:</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/28146E5F-3F27-4D41-94B7-CF6EF7615505/46004B64-228E-4F69-B607-D0FBBF391149_2/AbByT341edypWUhHSsEY1F3qSAmSIf9KuHJwYVgzJQ0z/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>Image pull with eStargz:</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/28146E5F-3F27-4D41-94B7-CF6EF7615505/495F26BE-BA38-48DF-B3F6-9915FDF52E5C_2/N7tCcNUyi2GGlpNmWfwIzNnBzbdmKsxhWnhSRUVkw7Mz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<h2 id=\"prefetching-files\">Prefetching files <a class=\"direct-link\" href=\"#prefetching-files\">#</a></h2>\n<p>What if you wanted the runtime to always download a file and disable lazy-pulling?</p>\n<p>eStargz supports prefetching of files. This mitigates runtime performance drawbacks caused by the on-demand fetching of each file.</p>\n<p>The example below always pulls <code>ls</code> and <code>bash</code> files before starting the container:</p>\n<pre class=\"language-python\"><code class=\"language-python\">$ cat <span class=\"token operator\">&lt;&lt;</span>EOF <span class=\"token operator\">></span> <span class=\"token operator\">/</span>tmp<span class=\"token operator\">/</span>record<span class=\"token punctuation\">.</span>json<br><span class=\"token punctuation\">{</span> <span class=\"token string\">\"path\"</span> <span class=\"token punctuation\">:</span> <span class=\"token string\">\"/usr/bin/bash\"</span> <span class=\"token punctuation\">}</span><br><span class=\"token punctuation\">{</span> <span class=\"token string\">\"path\"</span> <span class=\"token punctuation\">:</span> <span class=\"token string\">\"/usr/bin/ls\"</span> <span class=\"token punctuation\">}</span><br>EOF<br>$ nerdctl image convert <span class=\"token operator\">-</span><span class=\"token operator\">-</span>estargz <span class=\"token operator\">-</span><span class=\"token operator\">-</span>oci \\<br>    <span class=\"token operator\">-</span><span class=\"token operator\">-</span>estargz<span class=\"token operator\">-</span>record<span class=\"token operator\">-</span><span class=\"token keyword\">in</span><span class=\"token operator\">=</span><span class=\"token operator\">/</span>tmp<span class=\"token operator\">/</span>record<span class=\"token punctuation\">.</span>json \\<br>    ubuntu<span class=\"token punctuation\">:</span><span class=\"token number\">21.04</span> ubuntu<span class=\"token punctuation\">:</span><span class=\"token number\">21.04</span><span class=\"token operator\">-</span>ls</code></pre>\n<h2 id=\"seekable-oci-(soci)\">Seekable OCI (SOCI) <a class=\"direct-link\" href=\"#seekable-oci-(soci)\">#</a></h2>\n<p>Seekable OCI (SOCI) is a technology open sourced by AWS that enables containers to launch faster by lazily loading the container image. SOCI works by creating an index (SOCI Index) of the files within an existing container image. This index is a key enabler to launching containers faster, providing the capability of extracting an individual file from a container image before downloading the entire archive.</p>\n<p>SOCI borrows some of the design principles from stargz-snapshotter, but takes a different approach.</p>\n<p>A SOCI index is generated separately from the container image, and is stored in the registry as an <a href=\"https://github.com/opencontainers/artifacts\">OCI Artifact</a> and linked back to the container image by <a href=\"https://github.com/opencontainers/tob/blob/main/proposals/wg-reference-types.md\">OCI Reference Types</a>. This means that the container images do not need to be converted, image digests do not change, and image signatures remain valid.</p>\n<p>Most OCI registries like DockerHub and ECR do not currently support the &quot;referrers&quot; feature. So you cannot use SOCI unless you run a local <a href=\"https://oras.land\">ORAS</a> registry.</p>\n<h2 id=\"conclusion\">Conclusion <a class=\"direct-link\" href=\"#conclusion\">#</a></h2>\n<p>If you are looking to reduce container start time for your workloads, eStargz snapshotter is definitely worth a look. You’ll have to change your existing container build pipelines to add a step to convert images though. When SOCI support is available in OCI registries, you’ll be able to lazily-pull images without converting them first.</p>\n<p>You’ll also have to install eStargz snapshotter on your nodes and configure containerd to use the plugin. Creating a custom AMI or using AWS Systems manager will be the best way to do that. You could also use a DaemonSet to configure the system, but keep in mind that you’ll need to account for restarting the containerd and kubelet.</p>\n",
      "date_published": "2022-10-24T17:00:00-07:00"
    },{
      "id": "https://blog.realvarez.com/posts/handling-feedback/",
      "url": "https://blog.realvarez.com/posts/handling-feedback/",
      "title": "Handling Feedback",
      "content_html": "<p>Accepting feedback with grace plays a key role in building long lasting productive relationships. Humans are social creatures and feedback fuels our psyche. We nod when we see our colleagues in the hallway. Sometimes multiple times a day. We wave to our neighbors we rarely know, and we seek recognition from those we look up to.</p>\n<p>While positive feedback is invigorating, negative feedback about something we care deeply about can hinder our creativity. Especially when negative feedback carries hints of criticism and personal attacks.</p>\n<p>I have been in so many situations where leaders crush inventiveness with their <em>brutally honest</em> facts. These leaders think they are providing feedback, but they end up shaming attempts at innovation. Although inadvertent, their methods focus on individual rather than the product they are supposed to be improving.</p>\n<p>A survey by <a href=\"https://www.talentinnovation.org/\">the Center of Talent Innovation</a> found that when undermining management causes burnouts. This leadership style fosters an environment that becomes hostile to failure, and therefore, innovation.</p>\n<p>Collaborative creativity thrives in <em>psychologically safe</em> environments. When people believe others will not penalize them or think less of them for mistakes, they are more likely to take chances and think outside of the box. Isn’t that what management asks us all to do?</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/85595440-9377-4C01-B155-23C96FE4B91B/DB390C2D-FEE3-42F8-928D-96FEA52E0FA4_2/FGxQcbVgE38Dm7OknbK4Krt5tw9Ym1Z3b9J2aGRpcQoz/Image.png\" alt=\"Image.png\"></p>\n<p>Harvard Business School professor Amy Edmondson in <a href=\"https://web.mit.edu/curhan/www/docs/Articles/15341_Readings/Group_Performance/Edmondson%20Psychological%20safety.pdf\">Psychological Safety and Learning Behavior in Work Teams</a> writes:</p>\n<blockquote>\n<p>Team psychological safety should facilitate learning behavior in work teams because it eases excessive concern about others’ reactions to actions that have the potential for embarrassment or threat, which learning behaviors often have. For example, team members may be unwilling to bring up errors that could help the team make subsequent changes because they are concerned about being seen as incompetent, which allows them to ignore or discount the negative consequences of their silence for team performance. In contrast, if they respect and feel respected by other team members and feel confident that team members will not hold the error against them, the benefits of speaking up are likely to be given more weight.</p>\n</blockquote>\n<p>Negative criticism may be discouraging, whether you're getting it for a creative project or at a performance review. Many of us can recall at least one occasion when we were told that we were not good enough. Brene Brown refers to these moments as <em>creativity scars.</em> Brown learned that  85% people had a school incident in their childhood that was so shaming, it changed their perception about themselves.</p>\n<p>It remains an unfortunate fact that creativity, despite its inherent challenges, has to survive in environments designed to crush it. Pianists, singer, actors, or software developers, we all fight against the failure and self-doubt, not only in themselves but also in others. Open any business book and you’ll hear story after story of interpersonal conflicts and team dynamics stifling innovation.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/85595440-9377-4C01-B155-23C96FE4B91B/29954455-96B5-4109-9D48-C7F80A2FB741_2/7M1InpeGb4ctAfTV1fWfObn8IwAuUSnOsfyWPR1gha0z/Image.tiff\" alt=\"Image.tiff\"></p>\n<p>Negative feedback is everyone’s reality. I am staunch believer that <em>mastery requires feedback</em>. Maturity is in understanding that everyone fails. Failure is in remaining knocked down. Getting back into the game, and learning from your mistakes, is the way to fight failure. Even superstars are not immune to failure and criticism.</p>\n<p>One way to reduce negative feedback is by selecting the “right people”. This is an unreasonable expectation in professional environments. Or in <em>any</em> environment. I am not suggesting that you should care about everyone’s opinion. However, listening to a limited set of people can lead you in the wrong direction or groupthink. I am a proponent of diversity, and that includes seeking feedback from folks across the spectrum.</p>\n<h3 id=\"maintaining-growth-mindset\"><strong>Maintaining growth mindset</strong> <a class=\"direct-link\" href=\"#maintaining-growth-mindset\">#</a></h3>\n<p>I have learned that most feedback recipients need to carry a sieve to sift through the message. Surely there will be times when you’ll find nothing worthy to keep. But assuming you are asking the people that truly care about improving your contributions, there will be nuggets of good ideas to help you improve.</p>\n<p>When receiving negative (or poorly presented) feedback, you have two options. First is to simply ignore it, which might be great if you are an unconventional genius like Dostoevsky or Lady Gaga. The other option is to validate the feedback and seek things that can polish your work. I deal with the second situation. Most of the time.</p>\n<p>The worst you can do in these cases is to focus on the hurtful comments. Instead, listen. Be prepared to accept the feedback. Becoming defensive will hinder your ability to understand diverse viewpoints.</p>\n<p>Remain gracious as being thankful can disarm people intending to hurt you. Thank people for their time and effort. Don’t sound flippant or use sarcasm to shield yourself. Use this opportunity to learn. Don’t damage your relationships.</p>\n<blockquote>\n<p>Brown writes <em>“don’t grab hurtful comments and pull them close to you by rereading them and ruminating on them. Don’t play with them by rehearsing your badass comeback. And whatever you do, don’t pull hatefulness close to your heart.”</em></p>\n</blockquote>\n<p>When I recently faced hurtful feedback, I asked myself why does it sting. I carried elaborate chats with my opponent in my head. At first, I tried very hard to prove them wrong. Then I tried to disqualify their arguments. Then I discredited them. “What do they know?”</p>\n<p>They had hurt me with their comments. I allowed myself to wallow. I tried to put my feelings into words. In retrospective, the best thing I did was to avoid belittling myself, which I knew would’ve been a giant waste of time. I realized that the feedback was hard to process because it attacked my vulnerabilities. It had questioned my credibility.</p>\n<p>Many of us carry self-doubt deep within ourselves. There’s a strong link that connects our insecurities and the things that are important to us. We are worried that we’re not as competent or informed as we (or others) think we are. We live in a perpetual state of <a href=\"https://www.google.com/search?client=safari&amp;rls=en&amp;q=imposter+syndrome&amp;ie=UTF-8&amp;oe=UTF-8\"><em>imposter syndrome</em></a>.</p>\n<p>For reassurance, I remembered my past accomplishments. Practiced a bit of self-compassion. I couldn’t let an opinion define who I was. I had to isolate the feedback and the feelings it had brought to surface, and continue with my productive journey onward.</p>\n<p>The feedback provider had evoked my insecurities. The negative feelings triggered my defense mechanism setting my brain into flight or fight mode. In defensive mode, I was spending more energy fighting the feedback, berating myself, and feeling inadequate than using the feedback to improve my output. My fears made me think that the person saw my <em>authentic</em> version, the one that’s a total failure.</p>\n<p>It took me a couple of days to <em>calm down</em>. It couldn’t have been possible if I hadn’t processed my feelings and analyzed my thoughts. Ultimately, I did succeed in putting aside the negative stuff and focusing on the constructive feedback.</p>\n<p>In this situation, I realized that the feedback did make sense, and if roles were switched, I would’ve made the same recommendations. Albeit in a more professional and positive way.</p>\n<h3 id=\"set-clear-boundaries\"><strong>Set clear boundaries</strong> <a class=\"direct-link\" href=\"#set-clear-boundaries\">#</a></h3>\n<p>The incident definitely taught me that good feedback can sound outrageous at first (vice versa is also true). I am certainly not going to exclude people with tough feedback nor the ones that don’t know how to provide it. I am now more aware that my insecurities can make me stop listening and hinder my creativity.</p>\n<p>In fact, I intend to go a step further and welcome negative feedback. Not because I am a glutton for punishment, but because I know people struggle to provide positive feedback.</p>\n<p>When soliciting feedback, consider being specific and request feedback frequently. Doing so will give you inputs in more manageable portions.</p>\n<p>The right way to provide feedback is to put the problem in focus and not personalities. I positive feedback session for me is where I don’t come across as lecturer. I try to identify strengths in teams and individuals, and instances where that strength has potential to grow. The requestor and provider have to remain respectful at all times. I know people will not accept my feedback if I shame or blame them.</p>\n<p>When providing feedback, I need to choose my words wisely. The recipient is asking for help, not judgement. I can avoid sounding negative by first seeking permission to provide feedback and clearly defining the scope of feedback. By setting boundaries, I hope to ensure not stepping outside the scope of feedback I am being asked to provide. I cannot erode trust in relationships by sounding egoistic, self-righteous, and becoming an impediment to innovation.</p>\n",
      "date_published": "2022-10-08T17:00:00-07:00"
    },{
      "id": "https://blog.realvarez.com/posts/ebpf-speed-explained/",
      "url": "https://blog.realvarez.com/posts/ebpf-speed-explained/",
      "title": "How is eBPF efficient for observability",
      "content_html": "<blockquote>\n<p>Everybody says eBPF is fast, but how?</p>\n</blockquote>\n<p>The Berkeley Packet Filter (BPF or eBPF) is a virtual machine based on registers, initially designed for filtering network packets, best known for its use in <code>tcpdump</code>. In this post, we learn what is exactly that makes BPF so appealing for a number of use cases.</p>\n<h2 id=\"introduction\">Introduction <a class=\"direct-link\" href=\"#introduction\">#</a></h2>\n<p>BPF programs are small programs that run in the Linux kernel when events occur. You can think of BPF programs as event driven functions (like AWS Lambda).  BPF has access to a subset of kernel functions and memory. It is designed to be safe, that is poor BPF code won’t crash your kernel.</p>\n<p>In the containers world, BPF is increasingly becoming relevant. Its most popular use case is Cilium, which uses eBPF to provide a <a href=\"https://cilium.io/blog/2021/12/01/cilium-service-mesh-beta\">“sidecarless” service mesh</a> and <a href=\"https://github.com/pixie-io/pixie\">Pixie</a>, which uses eBPF to collect telemetry data.</p>\n<p>Other popular BPF uses are:</p>\n<ul>\n<li><strong>Debugging and Tracing -</strong> trace any <code>syscall</code> or kernel function or any user space program.\n<ul>\n<li><a href=\"https://github.com/iovisor/bpftrace\">bpftrace</a> allows users to trace from the Linux command line.</li>\n</ul>\n</li>\n<li><strong>Networking -</strong> Inspect, filter, manipulate traffic.\n<ul>\n<li>User space program can attach a filter to any socket and inspect the traffic flowing through it. They can also allow, disallow, redirect packets.</li>\n</ul>\n</li>\n<li><strong>Security monitoring and sandboxing</strong>\n<ul>\n<li>BPF programs can detect and report the <code>syscalls</code> occurring on a system.</li>\n<li>BPF programs can prevent applications from performing certain <code>syscalls</code> on a system (e.g., prevent deleting a file).</li>\n</ul>\n</li>\n</ul>\n<p>Linux has allowed us to perform above functions for decades, but BPF helps us perform these tasks more efficiently. BPF programs use fewer CPU and memory resources than traditional solutions.</p>\n<h2 id=\"how-is-bpf-faster%3F\">How is BPF faster? <a class=\"direct-link\" href=\"#how-is-bpf-faster%3F\">#</a></h2>\n<p>BPF programs are faster because BPF code runs in kernel space.</p>\n<p>Consider the steps a program has to take to calculate the number of bytes sent out on a Linux system. First, the kernel generates raw data as network activity occurs. This raw data packs a ton of information, most of which is irrelevant for calculating <em>bytes out</em> metrics. So, whatever is generating aggregated metrics will have to  filter the relevant data points repeatedly and run mathematical calculations on them. This process is repeated hundreds of times (or more) every minute.</p>\n<p>Since traditional monitoring programs run in user space, all that raw data that the kernel generates has to be copied from kernel space into user space. This data copy and filtering operation can be very taxing on the CPU. This is why ptrace is slow (whereas <a href=\"https://github.com/iovisor/bpftrace\"><code>bpftrace</code></a> is not).</p>\n<p>eBPF avoids this copying of data from kernel space to user space. You can run a program in kernel space to aggregate the data you need and send just the output to user space.</p>\n<p>Before BPF, large amounts of raw data from the kernel had to be copied over to user space for analysis. BPF allows creating histograms and filtering data within the kernel, which is much faster than exchanging massive amounts of data between user and kernel space.</p>\n<h2 id=\"bpf-maps\">BPF Maps <a class=\"direct-link\" href=\"#bpf-maps\">#</a></h2>\n<p>BPF uses <strong>BPF maps</strong> to allow bidirectional data exchange between user and kernel space. In Linux, maps are a generic storage type for sharing data between user and kernel space. They are key value stores that reside in the kernel.</p>\n<p>For metrics generation, BPF programs run calculations in kernel space and write results to BPF maps that a userspace  application can read (and also write to).</p>\n<hr>\n<p>Now you know why eBPF is efficient. It’s because BPF provides a way to run programs in kernel space and avoid copying irrelevant data between kernel and userspace.</p>\n<h2 id=\"references\">References <a class=\"direct-link\" href=\"#references\">#</a></h2>\n<p><a href=\"https://thenewstack.io/how-ebpf-streamlines-the-service-mesh\">How eBPF Streamlines the Service Mesh</a></p>\n<p><a href=\"https://buoyant.io/2022/06/07/ebpf-sidecars-and-the-future-of-the-service-mesh/\">eBPF, sidecars, and the future of the service mesh</a></p>\n<p><a href=\"https://av.tib.eu/media/44349\">TIB AV-Portal</a></p>\n<p><a href=\"https://www.amazon.com/Linux-Observability-BPF-Programming-Performance/dp/1492050202\">Linux Observability with BPF: Advanced Programming for Performance Analysis and Networking</a></p>\n<hr>\n<h2 id=\"appendix\">Appendix <a class=\"direct-link\" href=\"#appendix\">#</a></h2>\n<p>Containers use Linux Namespaces, a feature of the Linux kernel that partitions kernel resources such that one set of processes sees one set of resources while another set of processes sees a different set of resources.</p>\n<p>Under the hood, containers use <code>iptables</code> to network. Linux developers didn’t intend to run thousands of <code>iptables</code> rules on every node. To overcome the performance limitations in <code>iptables</code>, kernel devs are replacing <a href=\"https://cilium.io/blog/2018/04/17/why-is-the-kernel-community-replacing-iptables\"><code>iptables</code> with BPF</a>.</p>\n<h2 id=\"bpf-verifier\">BPF Verifier <a class=\"direct-link\" href=\"#bpf-verifier\">#</a></h2>\n<p>BPF allows anyone to run code in kernel space without being a kernel dev, compiling your own kernel, or writing custom kernel extensions that can hugely reduce the stability of the kernel.</p>\n<p>BPF programs are safe. The <strong>BPF Verifier</strong> ensures code is safe to run in kernel.   ← <strong>Explain this</strong></p>\n<p>Linux kernel includes a JIT compiler for BPF instructions. Once verification completes, JIT transforms bytecode to machine code.</p>\n<h2 id=\"bpf-programs\">BPF programs <a class=\"direct-link\" href=\"#bpf-programs\">#</a></h2>\n<p>Written in a subset of C. LLVM compiles BPF programs into bytecode.</p>\n<p><strong>BPF tracepoints</strong> are static marks in the kernel’s codebase that allow you to inject any code for tracing and debugging.</p>\n<h2 id=\"ebpf-and-mtls\">eBPF and mTLS <a class=\"direct-link\" href=\"#ebpf-and-mtls\">#</a></h2>\n<p>eBPF cannot do mTLS because it operates in kernel space entirely.</p>\n<p>Proxy mTLS is handled by the sidecar, which runs in the user space.</p>\n<h2 id=\"tcpdump-and-seccomp\">tcpdump and Seccomp <a class=\"direct-link\" href=\"#tcpdump-and-seccomp\">#</a></h2>\n<p>Generate BPF bytecode.</p>\n<p>tcpdump is frontend to <code>libpcap</code>. It reads packets from the NIC and writes to a file. PCAP filter on Linux are compiled to BPF programs. When you use <code>tcpdump</code> , you compile and load a BPF program to filter packets.</p>\n<h2 id=\"kubectl-trace\">kubectl trace <a class=\"direct-link\" href=\"#kubectl-trace\">#</a></h2>\n<p><a href=\"craftdocs://open?blockId=245EFFA2-BA97-4186-932A-F96888BF9F32&amp;spaceId=9d54cc03-adfe-f72f-3389-565eb7356d1d\"><strong>kubectl-trace</strong></a></p>\n",
      "date_published": "2022-07-08T17:00:00-07:00"
    },{
      "id": "https://blog.realvarez.com/posts/weak-references/",
      "url": "https://blog.realvarez.com/posts/weak-references/",
      "title": "Weak References - A weapon against Out Of Memory Errors",
      "content_html": "<p>One of the key features that containers offer us is the ability to apply resource control through <a href=\"https://man7.org/linux/man-pages/man7/cgroups.7.html\">Control Groups</a>, generally referred to as cgroups. Containers, which build on top of Linux cgroups, allow us to run process that have limited access to host's total capacity.</p>\n<p>This ability allows us to co-locate containers on the same host without being concerned that a container may impact other containerized apps, the so called <em>noisy neighbor problem</em>.</p>\n<p>While cgroups allow us to control many resources, the most used controls are CPU and memory. For scalable, multi-tenant clusters like Kubernetes or Amazon ECS, resource limiting is a best practice.</p>\n<p>ECS and Kubernetes allow us to limit resource consumption at container and ECS task or Kubernetes pod level. Below are the requests and limits a pod can have:</p>\n<ul>\n<li><code>spec.containers[].resources.limits.cpu</code></li>\n<li><code>spec.containers[].resources.limits.memory</code></li>\n<li><code>spec.containers[].resources.limits.hugepages-</code></li>\n<li><code>spec.containers[].resources.requests.cpu</code></li>\n<li><code>spec.containers[].resources.requests.memory</code></li>\n<li><code>spec.containers[].resources.requests.hugepages-</code></li>\n</ul>\n<p>Similarly, Docker desktop allows configuring memory and CPU limits. Should a container try to use more memory than allocated, it gets <em>killed</em>.</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token punctuation\">[</span><span class=\"token number\">336546.736392</span><span class=\"token punctuation\">]</span> Out of memory<span class=\"token punctuation\">:</span> Kill process <span class=\"token number\">9218</span> <span class=\"token punctuation\">(</span>java<span class=\"token punctuation\">)</span> score <span class=\"token number\">330</span> <span class=\"token keyword\">or</span> sacrifice child<br><span class=\"token punctuation\">[</span><span class=\"token number\">336546.738454</span><span class=\"token punctuation\">]</span> Killed process <span class=\"token number\">9218</span> <span class=\"token punctuation\">(</span>java<span class=\"token punctuation\">)</span> total<span class=\"token operator\">-</span>vm<span class=\"token punctuation\">:</span>7543324kB<span class=\"token punctuation\">,</span> test<span class=\"token operator\">-</span>mem<span class=\"token punctuation\">:</span>1060364kB<span class=\"token punctuation\">,</span> test<span class=\"token operator\">-</span>mem2<span class=\"token punctuation\">:</span>0kB<span class=\"token punctuation\">,</span> test<span class=\"token operator\">-</span>mem<span class=\"token operator\">-</span>rar<span class=\"token punctuation\">:</span>0kB<br><span class=\"token punctuation\">[</span><span class=\"token number\">336547.071919</span><span class=\"token punctuation\">]</span> oom_reaper<span class=\"token punctuation\">:</span> reaped process <span class=\"token number\">9218</span> <span class=\"token punctuation\">(</span>java<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> now test<span class=\"token operator\">-</span>mem<span class=\"token punctuation\">:</span>0kB</code></pre>\n<h2 id=\"memory-limits\">Memory Limits <a class=\"direct-link\" href=\"#memory-limits\">#</a></h2>\n<p>Many enterprises are in the process of moving legacy applications to containers clusters. Some of these applications ran on dedicated hardware. Their business requirements didn’t include operating with resource constraints.</p>\n<p>Having dedicated resources meant that traditional applications were free to consume as much system resources as available. Although Java allows us to control the heap size, it is rarely used to restrict memory usage for production applications.</p>\n<p>When these applications migrate to containers and a limit is put upon their memory consumption, new out of memory errors may emerge. A common remedy is to allocate more memory until the application stops crashing.</p>\n<p>In many cases, that might be the best solution. Pay a bit more of RAM, and move on. Code rot makes changes expensive with each passing day. But if you do have the resources to refactor code, optimizing memory consumption will improve the reliability of your applications.</p>\n<h2 id=\"%F0%9F%A7%B9-garbage-collection\">🧹 Garbage Collection <a class=\"direct-link\" href=\"#%F0%9F%A7%B9-garbage-collection\">#</a></h2>\n<p>One question we may want to ask ourselves is: What are some of the common ways of using memory inefficiently? Once you’ve fixed all the memory leaks, what’s next?</p>\n<p>C programmers had to manage memory manually using malloc() and free(). Thankfully, higher-level languages automatically allocate memory when programs create objects and free memory when the object is not required.</p>\n<p>When a process creates a new object, the system will allocate it memory and return the pointer to the program. Typically, a program’s variables (or objects) will remain in memory as long as the code is running. In programming languages like Python, objects include a reference count field, which counts how many objects are referencing it. JavaScript object has a reference to its prototype (implicit reference) and to its properties values (explicit reference). As long as an object has a non-zero reference, it’s immune to garbage collection.</p>\n<p>Once the process terminates, the garbage controller is free to remove the associated objects from memory as they don’t have any references. Objects created like these have a strong reference, which is the default behavior in all programming languages. They remain in memory until the process terminates.</p>\n<h3 id=\"%F0%9F%91%89%F0%9F%8F%BC-weak-referencing\">👉🏼 Weak Referencing <a class=\"direct-link\" href=\"#%F0%9F%91%89%F0%9F%8F%BC-weak-referencing\">#</a></h3>\n<p>One way to reduce memory consumption is by decreasing the amount and size of the objects stored in memory.</p>\n<p>Many languages also support creating objects with weak reference. Garbage collectors can remove any variable stored with weak reference even while the process that created it is still running. This provides an excellent way to store objects in memory that can be safely removed if the system comes under memory pressure.</p>\n<p>Weak Reference objects allow applications to safely build caches without risking running out of memory.</p>\n<h3 id=\"%F0%9F%8F%81-downsides-of-weak-referencing\">🏁 Downsides of weak referencing <a class=\"direct-link\" href=\"#%F0%9F%8F%81-downsides-of-weak-referencing\">#</a></h3>\n<p>Weak referencing forms the foundation for caching. And, similar to caching, it requires <em>getting and setting</em> a variable before usage. So, checking a variable if it exists before reading or writing to it is necessary for weak references.</p>\n<p>Can you imaging what would happen if a process tries to read its variable that’s stored as a weak reference, and the garbage controller has deleted it? Nothing good.</p>\n<h3 id=\"%F0%9F%8E%9A-different-levels-of-weak-references\">🎚 Different levels of weak references <a class=\"direct-link\" href=\"#%F0%9F%8E%9A-different-levels-of-weak-references\">#</a></h3>\n<p>In addition to the weak references described above, languages like Java provide <em>Soft References</em> and <em>Phantom References.</em> Here's an <a href=\"https://dzone.com/articles/weak-soft-and-phantom-references-in-java-and-why-they-matter\">article</a> that goes over the differences. The TLDR is that the garbage collector removes weak references first, then soft references, and finally phantom references.</p>\n<p>If your language provides different levels of weak references, consider choosing one that suits your application's requirements.</p>\n<h3 id=\"%F0%9F%AB%B1%F0%9F%8F%BD%E2%80%8D%F0%9F%AB%B2%F0%9F%8F%BC-external-caching\">🫱🏽‍🫲🏼 External caching <a class=\"direct-link\" href=\"#%F0%9F%AB%B1%F0%9F%8F%BD%E2%80%8D%F0%9F%AB%B2%F0%9F%8F%BC-external-caching\">#</a></h3>\n<p>If your application runs multiple replicas or if multiple processes are caching similar data, consider using Redis or Memcached as an external, distributed, and shared cache. These caching solutions are excellent for web services as they allow multiple replicas to share a cache, which allow us to store user’s sessions state without requiring sticky sessions.</p>\n<h2 id=\"%F0%9F%8F%86-bonus-tip\">🏆 Bonus tip <a class=\"direct-link\" href=\"#%F0%9F%8F%86-bonus-tip\">#</a></h2>\n<p>Another common cause for OOM errors in web applications is not keeping the payload size minimal. Web servers stores data for every session in memory until the session terminates. When a client requests a large payload, and the server doesn’t limit it, the systems stores the payload in memory before it is sent to the client.</p>\n<p>We can limit the payload size by restricting the maximum amount of data sent to a particular client. For example, you can paginate results from a database instead of sending the entire dataset to the client.</p>\n<h2 id=\"references\">References <a class=\"direct-link\" href=\"#references\">#</a></h2>\n<p><a href=\"https://docs.python.org/3/library/weakref.html\">weakref — Weak references — Python 3.10.4 documentation</a></p>\n<p><a href=\"https://indradhanush.github.io/blog/life-of-a-container/\">Life of a Container</a></p>\n<p><a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Memory_Management\">Memory Management - JavaScript | MDN</a></p>\n",
      "date_published": "2022-05-27T17:00:00-07:00"
    },{
      "id": "https://blog.realvarez.com/posts/observability-custom-metrics/",
      "url": "https://blog.realvarez.com/posts/observability-custom-metrics/",
      "title": "Close observability gaps with custom metrics",
      "content_html": "<blockquote>\n<p><em>Which application metrics should you collect?</em></p>\n</blockquote>\n<p>I frequently engage with customers that are amid breaking their monolithic applications into smaller microservices. Many teams with also see this migration as an opportunity to make applications more observable. As a result, customers inquire which metrics they should monitor for a typical cloud native application.</p>\n<p>Previously, when a customer asked me how to instrument a service, I pointed them to the well known <a href=\"https://grafana.com/blog/2018/08/02/the-red-method-how-to-instrument-your-services/\">USE and RED methods</a>. But, I felt the response wasn’t thorough. A list of specific metrics to monitor can be helpful for teams building cloud native applications. This post is an attempt to provide a list of metrics to collect in a typical application. Not all the metrics listed below apply to every application type. For example, batch-like workloads rarely serve traffic, and resultantly, don't need to keep a log of requests-served.</p>\n<p>The goal of this document is to help developers come up with the golden signals for their applications.</p>\n<blockquote>\n<p>Golden Signals, a term used first in the <a href=\"https://sre.google/sre-book/monitoring-distributed-systems/\">Google SRE handbook</a>. Golden Signals are four metrics that will give you a very good idea of the real health and performance of your application as seen by the actors interacting with that service, whether they are final users or another service in your microservice application.</p>\n</blockquote>\n<h2 id=\"observability\">Observability <a class=\"direct-link\" href=\"#observability\">#</a></h2>\n<p>Cloud best practices recommend building systems that are observable. While the word observability (or “<em>O11y</em>” as it is popularly known) doesn’t have an official definition, it is the measure of a system’s ability to expose its internal state. The three pillars of observability are logs, metrics, and traces.</p>\n<p>Modern systems are designed to produce logs, <em>emit</em> metrics, and provide traces to help developers and operators understand its internal state.</p>\n<blockquote>\n<p><a href=\"https://giedrius.blog/2019/05/11/push-vs-pull-in-monitoring-systems/\">Push vs Pull</a></p>\n</blockquote>\n<blockquote>\n<p>Emitting metrics by exposing them on an externally accessible HTTP endpoint is gaining wider adoption thanks to developers adopting Prometheus for monitoring. In this model, Prometheus pulls metrics by scraping the application’s <code>/metrics</code> endpoint.</p>\n</blockquote>\n<blockquote>\n<p>When you run Node Exporter, it publishes metrics at <code>http://localhost:9100/metrics</code></p>\n</blockquote>\n<p>Observability tools aggregate and analyze data from different sources to help you detect issues and identify bottlenecks. The goal is to use these system signals to improve its reliability and prevent downtime.</p>\n<p>AIOps products like <a href=\"https://aws.amazon.com/devops-guru/\">Amazon DevOps Guru</a> can also detect anomalies using your application's logs, metrics, and traces (and other sources) and give you early signals to prevent a potential disruption.</p>\n<h2 id=\"metrics-to-collect\">Metrics to collect <a class=\"direct-link\" href=\"#metrics-to-collect\">#</a></h2>\n<p>For an application to function as designed, the application and its underlying system have to be <em>healthy</em>. Host metrics inform the operator of the host’s and infrastructure resource usage, like CPU, memory, I/O, etc. If you use Prometheus, <a href=\"https://github.com/prometheus/node_exporter\">Node Exporter</a> collects this information automatically for you.</p>\n<p>Host metrics rarely differ. Whether we run a process on an EC2 instance or a Raspberry Pi, we’re interested in the same metrics.</p>\n<p>Unlike host metrics, application metrics are unique to each microservice. Application metrics are supposed to provide the operator the information so they can do these things:</p>\n<ol>\n<li>Identify future areas of improvement by providing code-specific measurements. Application monitoring or APM tools provide measurements over a segment of time that developers can analyze.</li>\n<li>When the system fails, provide information for troubleshooting and prevention.</li>\n<li>In some cases, provide early signals to business. For example, if the application exposes, the <em>orders</em> it has processed in the last 60 minutes can be tracked using the monitoring system, rather than querying a relational database.</li>\n</ol>\n<p>There are several companies like application monitoring or APM companies like New Relic, DataDog that have products to aggregate application metrics using SDKs or agents. However, what they will not collect are the business specific metrics that only your application cares about.</p>\n<p>In order to create a list of relevant metrics for an application, its architects will need to determine a signal for its every key function. The hallmark of a microservice is that it does <em>one thing well</em>, therefore it shouldn’t have many key functions. Start by white-boarding the functions implemented in the code and creating a list of metrics that would help you gauge its performance (or its availability at the least).</p>\n<p>Most measurements you’ll do will fall under one of these categories:</p>\n<h4 id=\"counter\">Counter <a class=\"direct-link\" href=\"#counter\">#</a></h4>\n<p>As the name suggests, this value is incremented when a function runs. Example: total requests served</p>\n<h4 id=\"histogram\"><a href=\"craftdocs://open?blockId=969CA66C-2955-405E-874A-E23D5F98AA26&amp;spaceId=9d54cc03-adfe-f72f-3389-565eb7356d1d\">Histogram</a> <a class=\"direct-link\" href=\"#histogram\">#</a></h4>\n<p>Histograms are charts that show the frequency of the occurrence of several ranges of values. A histogram samples observations (usually things like request durations or response sizes) and counts them in configurable buckets.</p>\n<h4 id=\"gauge\">Gauge <a class=\"direct-link\" href=\"#gauge\">#</a></h4>\n<p>This type is metric tracks a value that increases or decreases over a period. Example: number of threads.</p>\n<hr>\n<p>With that background, let’s go through the list of common custom metrics developers use.</p>\n<h3 id=\"network-activity\">Network activity <a class=\"direct-link\" href=\"#network-activity\">#</a></h3>\n<p>These are the obvious metrics to track for any application that serves traffic. Network metrics tell you how much load is placed on the system. Over the time, these data points assist you when devising the scaling strategy for the system.</p>\n<p>Things you should include are:</p>\n<ul>\n<li>Request count by API type or page</li>\n<li>Requests total</li>\n<li>Transactions</li>\n<li>Concurrent, expired, and rejected sessions</li>\n<li>A watermark that records maximum concurrent sessions</li>\n<li>Average processing time</li>\n<li>A count by error type</li>\n</ul>\n<h3 id=\"resource-usage\">Resource usage <a class=\"direct-link\" href=\"#resource-usage\">#</a></h3>\n<p>It is a best practice to monitor a systems <em>saturation</em>, which is a measure of your systems resource consumption. Every resource has a <em>breaking point</em>, beyond which additional stress causes performance degradation. Scalable and reliable systems are designed to never breach the breaking point.</p>\n<p>However, simply collecting overall resource saturation at an application level is insufficient. You also need to look deeper at thread or resource pool level.</p>\n<p>Consider collecting these metrics:</p>\n<ul>\n<li>Number of processors, system CPU load, process CPU load, available memory, used memory, available swap, used swap, open file descriptor count.</li>\n<li>Total resources consumed by connection pools, thread pools, and any other resource pools.</li>\n<li>Total started thread count, current thread count, current busy threads, keep alive count, poller thread count, and connection count.</li>\n<li>Objects created, destroyed, and checked out, high-water mark, number of times checked out,</li>\n<li>Number of threads blocked waiting for a resource, number of times a thread has blocked waiting</li>\n</ul>\n<p>Common frameworks like Tomcat, Flask, etc. support exporting pre-defined metrics. For example, JMX already exposes a bunch of these metrics. See <a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-Prometheus-Sample-Workloads-javajmx.html\">AWS CloudWatch documentation</a>.</p>\n<h3 id=\"users\">Users <a class=\"direct-link\" href=\"#users\">#</a></h3>\n<p>Besides, serving the intended audience, bots or scripts flood internet facing web servers with requests. These automated requests can overload the system if unauthenticated requests are improperly handled (for example, not redirecting all unauthenticated requests to the authentication service and attempting to process an unauthenticated request).</p>\n<p>Here are user related metrics to collect:</p>\n<ul>\n<li>Authenticated and unauthenticated requests</li>\n<li>Demographics, authenticated and unauthenticated requests, usage patterns,</li>\n<li>Unsuccessful login attempts</li>\n</ul>\n<p>Some of these metrics may also come from your Load Balancer or ingress.</p>\n<h3 id=\"business-transaction-(for-each-type)\">Business transaction (for each type) <a class=\"direct-link\" href=\"#business-transaction-(for-each-type)\">#</a></h3>\n<p>If your application follows the microservices approach, then the code fulfills one function, at least that’s the idea. What are the key performance indicators for your app’s function? Define them and track these metrics.</p>\n<p>Should future releases cause performance regression, you’ll be able to detect it. Tracking these business metrics will help you track trends easily and avoid a cascading failure.</p>\n<p>Here are common things that services care about:</p>\n<ul>\n<li>Orders, messages, requests, transactions processed</li>\n<li>Success and failure rates. For a retailer, this could be the conversion rate.</li>\n<li>Service level agreements (like average transaction response time)</li>\n</ul>\n<p>If you still need help with identifying key metrics, ask yourself this question: In what ways can my application negatively affect the business even when it might appear to be healthy?</p>\n<h3 id=\"database-connections\">Database connections <a class=\"direct-link\" href=\"#database-connections\">#</a></h3>\n<p>Along with monitoring your database instances using database monitoring tools, consider collecting database connection health metrics in your application. This is especially helpful if your application uses a shared database. If your application encounters database connection errors but the database remains operational for other application, you know the problem is on the application side, and not the database.</p>\n<p>Consider recording these databases-related metrics:</p>\n<ul>\n<li>A count of <code>SQLException</code> thrown</li>\n<li>Number of (concurrent or maximum)queries</li>\n<li>Average query run time</li>\n</ul>\n<h3 id=\"data-consumption\">Data consumption <a class=\"direct-link\" href=\"#data-consumption\">#</a></h3>\n<p>Wherever you’re persisting data, you need to ensure that you’re going to go over your quotas and run out of space. Besides, monitoring on disk and in-memory data volumes, don’t forget to monitor the data your application stores in databases and caches.</p>\n<h3 id=\"cache-health\">Cache health <a class=\"direct-link\" href=\"#cache-health\">#</a></h3>\n<p>Speaking of cache, it is a best practice to monitor these metrics:</p>\n<ul>\n<li>Items in cache</li>\n<li>Get and set latency</li>\n<li>Hits and miss rates</li>\n<li>Items flushed</li>\n</ul>\n<p>Also, consider using an external cache such as Redis or Memcached.</p>\n<h3 id=\"external-services\">External services <a class=\"direct-link\" href=\"#external-services\">#</a></h3>\n<p>Keeping a track of how downstream services perform is also useful in understanding issues. Along with using timeouts, retries (preferably with <a href=\"https://en.wikipedia.org/wiki/Exponential_backoff\">exponential backoff</a>), and circuit breakers, consider monitoring these metrics for every external service your service's proper functioning depends on:</p>\n<ul>\n<li>Circuit breaker status</li>\n<li>Count of timeouts, requests</li>\n<li>Average response time or latency</li>\n<li>Responses by type</li>\n<li>Network errors, protocol errors</li>\n<li>Requests in flight</li>\n<li>A high watermark of concurrent requests.</li>\n</ul>\n<h3 id=\"granularity-in-metrics-collection\">Granularity in metrics collection <a class=\"direct-link\" href=\"#granularity-in-metrics-collection\">#</a></h3>\n<p>The frequency at which you publish and collect metrics depends on your business requirements. For a retailer, knowing traffic patterns by the hour and day is useful in scaling capacity. Similarly, a travel company’s traffic pattern are influenced by holiday schedules.</p>\n<p>Amazon EC2 provides instance metrics at 1-minute interval, which is a good start for critical metrics.</p>\n<p>Remember that there’s a cost attached to exposing, collecting, and analyzing metrics. Collecting unnecessary information in metrics can put a strain on the system and slow down troubleshooting.</p>\n<p>Consider giving the operator the control over the metrics your code should generate. This way, you can turn on specific metrics whenever needed.</p>\n<h2 id=\"conclusion\">Conclusion <a class=\"direct-link\" href=\"#conclusion\">#</a></h2>\n<p>Finding out which metrics to collect is an answer that only the most familiar with the code can answer. This post provides a list of metrics for you to get started.</p>\n<p>Are there any metrics that I have overlooked? Let me know at <a href=\"https://twitter.com/realz\">@realz</a>.</p>\n<h2 id=\"references\">References <a class=\"direct-link\" href=\"#references\">#</a></h2>\n<p><a href=\"https://giedrius.blog/2019/05/11/push-vs-pull-in-monitoring-systems/\">Push Vs. Pull In Monitoring Systems – Giedrius Statkevičius</a></p>\n<p><a href=\"https://www.splunk.com/en_us/blog/learn/sre-metrics-four-golden-signals-of-monitoring.html\">SRE Metrics: Four Golden Signals of Monitoring</a></p>\n<p><a href=\"https://www.oreilly.com/library/view/learning-modern-linux/9781098108939/\">Learning Modern Linux</a></p>\n<p><a href=\"https://www.oreilly.com/library/view/release-it/9781680500264/\">Release It!</a></p>\n<h2 id=\"appendix\">Appendix <a class=\"direct-link\" href=\"#appendix\">#</a></h2>\n<h3 id=\"instrumentation\">Instrumentation <a class=\"direct-link\" href=\"#instrumentation\">#</a></h3>\n<p>Instrumentation is the way to measure an application’s performance. It is highly useful in profiling and troubleshooting. There are two common strategies for instrumentation:</p>\n<ul>\n<li>Auto instrumentation. This is generally done using a library like OpenTelemetry API and SDK. For more see “<a href=\"https://www.honeycomb.io/blog/what-is-auto-instrumentation/\">What Is Auto-Instrumentation?</a>”.</li>\n<li>Custom instrumentation. Whenever your instrumentation needs are not met by auto instrumentation, you will also generate custom metrics.</li>\n</ul>\n",
      "date_published": "2022-05-05T17:00:00-07:00"
    },{
      "id": "https://blog.realvarez.com/posts/book-review-12-rules-jp/",
      "url": "https://blog.realvarez.com/posts/book-review-12-rules-jp/",
      "title": "Book Review - 12 Rules for Life - Jordan Peterson",
      "content_html": "<p>Of all the books I have read, this has to be one of the most polarizing. I must admit that I started this book with a heavy bias against the author, thanks to his infamy on progressive subs on Reddit. The first few pages didn’t make it any easier; the prologue was filled with things that you’d see on a Twitter “#ShitDonaldTrumpSays” thread.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/7D92D31F-484C-458F-87D2-0566989F03F7/7323E51C-64C0-4940-8063-8FBE31429A1A_2/pKAZNxYoyn4QySBCTI4laKPof2JRUnKpuvWfeMLDt3Yz/Image\" alt=\"Image\"></p>\n<p>In the beginning, I found author’s self-righteous tone off-putting. I admit that I skipped pages whenever Bible was the sole exemplary. Gradually, though, I found myself agreeing more and more with the author, albeit at a very fundamental level. When I  agreed, I still found his method of deduction dubious and massively sexist.</p>\n<p>His points of reference, when it comes to sexism, are so flawed (in my humble opinion) that the reader is tempted to discount the author entirely, but if you wade through much of his ramblings, you may find a learning or two. At this point, you are better off reading a more concise self-help book because the author loves to ramble a lot. Which is fine for readers that don’t care about the length of the book. But if you’re reading this book for self-improvement, 1/ this is not the most well-written self-help book (its a good book though) and 2/ the author’s tone is polarizing, for almost every ethnicity, ideology, or sex.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/7D92D31F-484C-458F-87D2-0566989F03F7/7BC4C43E-4943-4F3B-BC14-2523A2464F8E_2/Dl5UyQmnDraSK2dQvHjNyu7RHZyxsYrodUox2ukUcAAz/Image\" alt=\"Image\"></p>\n<p>The book advocates a lot about masculinity. It’s innate aggression. How women, who failed as the leaders of ancient society, are on a constant pursuit to introduce feminine qualities such as “agreeableness” (who’d have thunk 🤯) to rein in the masculine aggression. The aggression should be fostered as it pushes young men to innovate so that they can get ride their bikes faster. Is the author saying that only men are capable of doing stupid stuff you'd generally see on MTV Jackass 🤔.</p>\n<p>Time and time again, the author justifies violence or aggression. I have a feeling the author and Will Smith will be good friends.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/7D92D31F-484C-458F-87D2-0566989F03F7/19272A08-8F3E-48E8-92FF-AD3DF1E6E7E4_2/l71ZKFKmFPX6KZ6efXLSFUfZgIHrFg99ulqXCRw2Iykz/Image\" alt=\"Image\"></p>\n<p>I find it interesting (to say the least) that despite being a psychologist, the author has things like to say:</p>\n<blockquote>\n<p>“Girls can win by winning in their own hierarchy—by being good at what girls value, as girls. They can add to this victory by winning in the boys’ hierarchy. Boys, however, can only win by winning in the male hierarchy. They will lose status, among girls and boys, by being good at what girls value. It costs them in reputation among the boys, and in attractiveness among the girls. <strong>Girls aren’t attracted to boys who are their friends, even though they might like them, whatever that means.</strong> They are attracted to boys who win status contests with other boys. If you’re male, however, you just can’t hammer a female as hard as you would a male. Boys can’t (won’t) play truly competitive games with girls. It isn’t clear how they can win. As the game turns into a girls’ game, therefore, the boys leave.</p>\n</blockquote>\n<p>So, basically rich woman should compare resumes before forming romantic ties 👍🏼. In my view the author's message is not <em>that</em> sexist, but it's definitely worded to encourage misinterpretations. Great writing or flawed ideology ⚖️?</p>\n<blockquote>\n<p>“If they’re healthy, women don’t want boys. They want men. They want someone to contend with; someone to grapple with. If they’re tough, they want someone tougher. If they’re smart, they want someone smarter. They desire someone who brings to the table something they can’t already provide. This often makes it hard for tough, smart, attractive women to find mates: there just aren’t that many men around who can outclass them enough to be considered desirable ”</p>\n</blockquote>\n<blockquote>\n<p>Men enforce a code of behavior on each other, when working together. Do your work. Pull your weight. Stay awake and pay attention. Don’t whine or be touchy. Stand up for your friends. Don’t suck up and don’t snitch. Don’t, in the immortal words of Arnold Schwarzenegger, be a <strong>girlie man</strong>. Don’t be dependent. At all. Ever. Period. The harassment that is part of acceptance on a working crew is a test: are you tough, entertaining, competent and reliable? If not, go away. Simple as that. We don’t need to feel sorry for you. We don’t want to put up with your narcissism, and we don’t want to do your work.”</p>\n</blockquote>\n<p>I was not surprised to learn that the author doesn’t believe in feminism. He goes on to say that women have little to contribute in many ways</p>\n<blockquote>\n<p>“Furthermore, even if women contributed nothing substantial to art, literature and the sciences prior to the 1960s and the feminist revolution (which is not something I believe), then the role they played raising children and working on the farms was still instrumental in raising boys and freeing up men—a very few men—so that humanity could propagate itself and strive forward.”</p>\n</blockquote>\n<p>In his opinion there have been many men like the tampon king of India that have advocated for women. I am still unclear how that justifies not believing in feminism but 🤷🏽‍♂️.</p>\n<p>I did enjoy author’s take on classics like Dostoevsky, Sartre, and other western European philosophers. Although, I found his interoperation of Hansel and Gretel hilarious 😂.</p>\n",
      "date_published": "2022-04-17T17:00:00-07:00"
    },{
      "id": "https://blog.realvarez.com/posts/how-much-do-eks-nodes-cost/",
      "url": "https://blog.realvarez.com/posts/how-much-do-eks-nodes-cost/",
      "title": "How much do my Amazon EKS nodes cost?",
      "content_html": "<p>If you want to know the cost of running Amazon EKS nodes, AWS Cost Explorer is your friend.</p>\n<p><a href=\"https://aws.amazon.com/aws-cost-management/aws-cost-explorer/\">AWS Cost Explorer</a> helps you analyze your AWS bill. Cost Explorer has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time.</p>\n<p>Cost Explorer supports breaking down costs using <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/Using_Tags.html\">tags</a>. A tag is a label that you assign to an AWS resource. Tags enable you to categorize your AWS resources by, for example, purpose, owner, or environment.</p>\n<p>Kubernetes cluster deployment tools like <code>eksctl</code> automatically add default tags to EC2 instances that are part of a managed node group. Customer can view tags attached to their nodes in the AWS Management Console.</p>\n<p>To view the tags attached to your EKS nodes, go to the AWS Management Console and inspect the tags. You can also use the <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeTags.html\"><code>DescribeTags</code> API</a> to query tags using AWS CLI or SDK.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/99997738-88A8-4420-9881-286553E32476_2/hqNzdOTLsvdLYOyrPn70lF2cToHkSbhIDtm4xr8RA08z/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>Pick an EC2 instance that's part of your EKS cluster, note its tags, select a tag, like <code>eks:cluster-name</code>, and verify that all nodes have that label. You will later use this tag to separate the costs of Kubernetes nodes from the rest of EC2 usage in your account(s).</p>\n<h2 id=\"activate-tags-in-billing\">Activate tags in billing <a class=\"direct-link\" href=\"#activate-tags-in-billing\">#</a></h2>\n<p>Once you have identified the tag using which you are going to identify EKS EC2 nodes, you’ll have to activate that tag in the AWS Billing and Cost Management console. You’ll need <a href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/control-access-billing.html\">privileges</a> to make changes.</p>\n<p>To activate your tags using the AWS Management Console:</p>\n<ol>\n<li>Sign in to the AWS Management Console and open the AWS Billing console at <a href=\"https://console.aws.amazon.com/billing/\">https://console.aws.amazon.com/billing/</a>.</li>\n<li>In the navigation pane, choose Cost Allocation Tags.</li>\n<li>Select the tags that you want to activate.</li>\n<li>Choose Activate.</li>\n</ol>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/263EE126-DAD2-4F52-856E-6F065BF89E53_2/AwhushwYYUHGexRRGMqTseZBAfi0u2rQP8k2k8xeNpoz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>After you select your tags for activation, it can take <strong>up to 24 hours</strong> for tags to activate.</p>\n<p>Billing has AWS-generated cost allocation tags that customers can use to identify costs.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/0C3F9990-AB32-4876-85EB-CE7F7D9E4C83/123DF0AF-8C9D-4625-8816-FF6A2511B596_2/lHrGroWK3tRZFJVuLqOdx2xPWKEEADFIo5teWiGeIbgz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<h2 id=\"view-charges-in-aws-cost-explorer\">View charges in AWS Cost Explorer <a class=\"direct-link\" href=\"#view-charges-in-aws-cost-explorer\">#</a></h2>\n<p>Navigate to AWS Cost Explorer and create a new report</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/3B13ED5A-B51C-4109-8D51-E3BC9187BF8A_2/dv6xOgqDiX8lQMHmPz0yqeySZ6OgPqEBAqRLyEifu3gz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>In the next screen, choose <strong>Cost and usage</strong>. Then scroll to the bottom of page and choose <strong>create report.</strong></p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/0C3F9990-AB32-4876-85EB-CE7F7D9E4C83/75A8974D-92E5-487B-8A66-F1DA634E81B0_2/aoYH9yyFtz8vHHrxMuthXXXaBlGYAuLdeUxbPeTqDCIz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>In the next screen, configure a <strong>Service</strong> filter, select EC2-Instances, and apply filter.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/0C3F9990-AB32-4876-85EB-CE7F7D9E4C83/A360630B-8E50-42EE-8245-C5AADFA5BFFC_2/wmtRAMwgAJWxXCTAMjeTGPogUhEmOdiBnRxOuTylyuYz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>Create a <strong>Tag</strong> filter, select the tag you activated in billing, and apply. Be sure to select only <code>true</code>.</p>\n<p>In my case, my nodes had the <code>eks:cluster-name</code> tag.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/doc/7B8C4159-87D5-4FBF-847F-0AA3DB34730C/22D7482D-E383-43BC-B123-5D4C805D7C52_2/PPl1BfJ7puxg0H4lPCLqyxpX58r4cEAO0R7iTzLRsLIz/Image\" alt=\"Image\"></p>\n<p>Now Cost Explorer shows just the charges for my cluster.</p>\n<p><img src=\"https://res.craft.do/user/full/9d54cc03-adfe-f72f-3389-565eb7356d1d/AE2DDB1D-DD37-409F-81C6-B5F447210571_2/YpYzKtND10nuEyoY0qifZWzkxyyX31CW511EIjI02xwz/Image.jpeg\" alt=\"Image.jpeg\"></p>\n<p>Now I know that in Feb ’22, I paid roughly $3000 for the nodes that are part of the cluster named “Socrates.”</p>\n",
      "date_published": "2022-02-04T16:00:00-08:00"
    }
  ]
}
